{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd01d755-cef0-4218-b673-be74dcac3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9791060-b2c1-4584-b0db-61c7bd66f251",
   "metadata": {},
   "source": [
    "## Simulating data\n",
    "\n",
    "We begin by simulating a population of genetic sequences over time with mutation and selection with `simulate_genetic_sequences_with_parents`. This function returns all sequences in the population as well as indices for parent child pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c541e54-d01e-498a-9552-25a302701d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def simulate_genetic_sequences_with_parents(\n",
    "    num_sequences: int,\n",
    "    sequence_length: int,\n",
    "    time_span: int,\n",
    "    fitness_fn: Callable,\n",
    "    mutation_rate: float,\n",
    "    time_dependent_fitness: bool = False,\n",
    "    fix_initial_population: bool = False\n",
    ") -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Simulate genetic sequences over time with mutation and selection.\n",
    "\n",
    "    Args:\n",
    "        num_sequences: Number of sequences in each generation.\n",
    "        sequence_length: Length of each sequence.\n",
    "        time_span: Number of generations to simulate.\n",
    "        fitness_fn: Function to calculate fitness for a sequence.\n",
    "        mutation_rate: Probability of mutation at each position in a sequence.\n",
    "        time_dependent_fitness: If True, fitness is a function of time.\n",
    "        fix_initial_population: If True, start with a fixed initial sequence.\n",
    "\n",
    "    Returns:\n",
    "        all_sequences: List of arrays, where each array has shape \n",
    "                       (num_sequences, sequence_length) and corresponds to a generation.\n",
    "        parent_child_indices: List of arrays, where each array has shape \n",
    "                              (num_sequences,) and indicates the parent index for each child.\n",
    "    \"\"\"\n",
    "    # Initialize the population with random sequences\n",
    "    if fix_initial_population:\n",
    "        initial_sequence = np.random.randint(0, 4, size=(sequence_length))\n",
    "        population = np.vstack([initial_sequence] * num_sequences)\n",
    "    else:\n",
    "        population = np.random.randint(0, 4, size=(num_sequences, sequence_length))\n",
    "\n",
    "    # Convert integers to nucleotides\n",
    "    nucleotides = np.array([\"A\", \"C\", \"G\", \"T\"])\n",
    "\n",
    "    sequences = nucleotides[population]\n",
    "\n",
    "    # List to store sequences and parent indices at all time steps\n",
    "    all_sequences = [nucleotides[population]]\n",
    "    parent_child_indices = []\n",
    "\n",
    "    for generation in range(time_span):\n",
    "        # Calculate fitness for each sequence\n",
    "        fitness = (\n",
    "            fitness_fn(sequences, generation)\n",
    "            if time_dependent_fitness\n",
    "            else fitness_fn(sequences)\n",
    "        )\n",
    "\n",
    "        # Select parents based on fitness (using weighted random sampling)\n",
    "        parent_indices = np.random.choice(\n",
    "            num_sequences,\n",
    "            size=num_sequences,\n",
    "            p=np.exp(fitness) / np.sum(np.exp(fitness)),\n",
    "        )\n",
    "        parents = sequences[parent_indices]\n",
    "\n",
    "        # Create offspring through mutation\n",
    "        offspring = parents.copy()\n",
    "        mutation_mask = np.random.random(offspring.shape) < mutation_rate\n",
    "        mutation_mask[:20] = 0\n",
    "        offspring[mutation_mask] = nucleotides[\n",
    "            np.random.randint(0, 4, size=int(np.sum(mutation_mask)))\n",
    "        ]\n",
    "\n",
    "        # Replace the population with the offspring\n",
    "        sequences = offspring\n",
    "\n",
    "        # Store the current generation's sequences and parent indices\n",
    "        all_sequences.append(sequences)\n",
    "        parent_child_indices.append(parent_indices)\n",
    "\n",
    "    return all_sequences, parent_child_indices\n",
    "\n",
    "def example_fitness_function(population):\n",
    "    # This is a simple fitness function that favors sequences with more 'A's\n",
    "    return np.sum(population == 'A', axis=1)\n",
    "\n",
    "def example_fitness_function(population, generation):\n",
    "    if generation < 140:\n",
    "        return np.sum(population == 'A', axis=1)\n",
    "    return 10.0 * np.sum(population != 'A', axis=1)\n",
    "\n",
    "num_sequences = 100\n",
    "sequence_length = 50\n",
    "time_span = 60\n",
    "mutation_rate = 0.05  # mutation rate per site\n",
    "\n",
    "all_sequences, parent_child_indices = simulate_genetic_sequences_with_parents(\n",
    "    num_sequences, \n",
    "    sequence_length, \n",
    "    time_span, \n",
    "    example_fitness_function, \n",
    "    mutation_rate,\n",
    "    time_dependent_fitness=True,\n",
    "    fix_initial_population=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7463ada-87c0-407f-922b-035042b817fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB32UlEQVR4nO3dd3wUdeLG8Wc32Wx6IySBENIAIXRClaqAKBbAAhYsoNjQUznPn5x3IDY8z7OeylkQu1gAKyoivfdeQyCQkAakh7Sd3x9IzlyAJJBkks3n/XrlBTszu/vMfkH3YWa+YzEMwxAAAAAA4KysZgcAAAAAgPqO4gQAAAAAlaA4AQAAAEAlKE4AAAAAUAmKEwAAAABUguIEAAAAAJWgOAEAAABAJShOAAAAAFAJihMAAAAAVILiBABAFSxevFgWi0WLFy82O0q9xucEwFlRnADgPG3btk3XX3+9IiIi5O7urrCwMA0dOlSvv/662dEatNNfvC0Wiz7++OMzbtO3b19ZLBZ16NDhvN7j008/1SuvvHIBKWtGYmKi7r33XkVGRsputys4OFgjR47UihUrzI5Wzh133FE2Juf6ueOOO8yOCgC1xmIYhmF2CABoaFauXKlLLrlELVu21O23367Q0FAdPnxYq1evVnx8vPbv3292xAZr8eLFuuSSS+Tu7q5LLrlEP/74Y7n1Bw8eVFRUlNzd3RUTE6Pt27dX+z2uuuoqbd++XQcPHqzycxwOh4qKiuTm5iar9cL/3XHFihUaPny4JOmuu+5SbGysUlJSNGvWLMXHx+vVV1/Vgw8+eMHvUxNWrVql+Pj4sscJCQmaMmWK7r77bvXv379seUxMjHr16lWjnxMA1BeuZgcAgIbo2WeflZ+fn9atWyd/f/9y69LS0swJ5WSGDx+ub7/9VhkZGQoKCipb/umnnyokJEStW7fWiRMnaj3HyZMny0qAu7t7jbzmiRMndP3118vDw0MrVqxQTExM2bpJkyZp2LBhevjhhxUXF6eLL764Rt6zKv64r3/Up08f9enTp+zx+vXrNWXKFPXp00djx46t8Do19TkBQH3CPwUBwHmIj49X+/btK5QmSQoODq6w7OOPP1ZcXJw8PDwUGBioG2+8UYcPH66w3dtvv62YmBh5eHioZ8+eWrZsmQYNGqRBgwaVbTNr1ixZLJYKR0vOdm3JmjVrdPnll8vPz0+enp4aOHBghVPBnnzySVksFu3fv1933HGH/P395efnp3Hjxik/P/+M+9OzZ095enoqICBAAwYM0C+//FJum/nz56t///7y8vKSj4+PrrzySu3YsaPCa53NiBEjZLfb9eWXX5Zb/umnn2r06NFycXE54/Mq+6wHDRqkH374QYcOHSo7xSwyMlLSfz/Dzz//XH/7298UFhYmT09PZWdnn/PzHT58uAICAuTl5aVOnTrp1VdfPee+/ec//1FKSor++c9/litNkuTh4aEPPvhAFotFTz31lKRTRcViseiDDz6o8Fo///yzLBaLvv/++7JlSUlJGj9+vEJCQmS329W+fXvNnDmz3PPOta8X4kyf06BBg9ShQwdt3bpVAwcOlKenp1q1aqWvvvpKkrRkyRL16tVLHh4euuiii/Trr79WeN2q7BMA1CaKEwCch4iICG3YsKFKp4k9++yzuu2229S6dWu99NJLevjhh7Vw4UINGDBAmZmZZdu99957uueeexQaGqoXXnhBffv21TXXXHPGglVVv/32mwYMGKDs7GxNnTpVzz33nDIzM3XppZdq7dq1FbYfPXq0cnJyNH36dI0ePVqzZs3StGnTym0zbdo03XrrrbLZbHrqqac0bdo0hYeH67fffivb5qOPPtKVV14pb29v/eMf/9Df//537dy5U/369avy6XGenp4aMWKEPvvss7JlW7Zs0Y4dO3TzzTef8TlV+ayfeOIJdenSRUFBQfroo4/00UcfVbje6emnn9YPP/ygRx99VM8995zc3NzO+H4LFizQgAEDtHPnTj300EP617/+pUsuuaRciTmT7777Tu7u7ho9evQZ10dFRalfv3767bffVFBQoO7duys6OlpffPFFhW1nz56tgIAADRs2TJKUmpqq3r1769dff9UDDzygV199Va1atdKdd955xuu6qrqvF+rEiRO66qqr1KtXL73wwguy2+268cYbNXv2bN14440aPny4nn/+eeXl5en6669XTk5O2XOru08AUCsMAEC1/fLLL4aLi4vh4uJi9OnTx3jssceMn3/+2SgqKiq33cGDBw0XFxfj2WefLbd827Zthqura9nyoqIiIzg42OjSpYtRWFhYtt3bb79tSDIGDhxYtuz99983JBkJCQnlXnPRokWGJGPRokWGYRiGw+EwWrdubQwbNsxwOBxl2+Xn5xtRUVHG0KFDy5ZNnTrVkGSMHz++3GuOGjXKaNKkSdnjffv2GVar1Rg1apRRWlpabtvT75GTk2P4+/sbEyZMKLc+JSXF8PPzq7D8f53ejy+//NL4/vvvDYvFYiQmJhqGYRh/+ctfjOjoaMMwDGPgwIFG+/bty55X1c/aMAzjyiuvNCIiIs763tHR0UZ+fv4Z153+fEtKSoyoqCgjIiLCOHHixBk/i7Px9/c3OnfufM5t/vSnPxmSjK1btxqGYRiTJ082bDabcfz48bJtCgsLDX9//3LjdueddxrNmjUzMjIyyr3ejTfeaPj5+ZXt17n2tTLr1q0zJBnvv/9+hXX/+zkZxqmxkmR8+umnZct2795tSDKsVquxevXqsuU///xzhdeu6j4BQG3iiBMAnIehQ4dq1apVuuaaa7Rlyxa98MILGjZsmMLCwvTtt9+WbTdnzhw5HA6NHj1aGRkZZT+hoaFq3bq1Fi1aJOnUqVhpaWm69957y/2L/x133CE/P7/zyrh582bt27dPN998s44dO1b23nl5eRo8eLCWLl0qh8NR7jn33ntvucf9+/fXsWPHyk7fmjdvnhwOh6ZMmVLhOhiLxSLp1FGYzMxM3XTTTeX22cXFRb169Srb56q47LLLFBgYqM8//1yGYejzzz/XTTfddMZtq/pZV8Xtt98uDw+Pc26zadMmJSQk6OGHH65wyubpz+JscnJy5OPjc85tTq8//dmPGTNGxcXFmjNnTtk2v/zyizIzMzVmzBhJkmEY+vrrr3X11VfLMIxyn8OwYcOUlZWljRs3Vntfa4K3t7duvPHGsscXXXSR/P391a5dO/Xq1ats+enfHzhw4Lz3CQBqA5NDAMB56tGjh+bMmaOioiJt2bJFc+fO1csvv6zrr79emzdvVmxsrPbt2yfDMNS6deszvobNZpMkHTp0SJIqbGez2RQdHX1e+fbt2yfp1Bfjs8nKylJAQEDZ45YtW5Zbf3rdiRMn5Ovrq/j4eFmtVsXGxlb6vpdeeukZ1/v6+lZtB3Rq/2+44QZ9+umn6tmzpw4fPnzW0/Sq+llXRVRUVKXbnJ5l7nymRPfx8Sl3KtqZnF5/ukB17txZbdu21ezZs3XnnXdKOnWaXlBQUNlnnZ6erszMTL399tt6++23z/i6/zt5SVX2tSa0aNGiQqH08/NTeHh4hWWSyib+OJ99AoDaQHECgAvk5uamHj16qEePHmrTpo3GjRunL7/8UlOnTpXD4ZDFYtH8+fPPOJmBt7d3td/vbEczSktLyz0+fTTpn//8p7p06XLG5/zv+59twgWjGneuOP2+H330kUJDQyusd3Wt3v96br75Zs2YMUNPPvmkOnfufNbSVpOfdW0fgWnXrp02bdqkwsJC2e32M26zdetW2Wy2ckVwzJgxevbZZ5WRkSEfHx99++23uummm8o+09Of/dixY89amDt16lTucV0cbZLO/mersj9z57NPAFAbKE4AUIO6d+8uSTp69KikU/e1MQxDUVFRatOmzVmfFxERIenUUZM/HqkpLi5WQkKCOnfuXLbs9FGgP04sIf33qNVpp2dr8/X11ZAhQ85zj8qLiYmRw+HQzp07z1rGTr9vcHBwjbxvv3791LJlSy1evFj/+Mc/zpmtKp+1VPmpdFVxej+3b99e7f286qqrtGrVKn355ZdnnM774MGDWrZsmYYMGVKu2IwZM0bTpk3T119/rZCQEGVnZ5c7/a1p06by8fFRaWlpjY252ZxxnwA0TFzjBADnYdGiRWc8CnP6Zq0XXXSRJOnaa6+Vi4uLpk2bVmF7wzB07NgxSacKV9OmTTVjxgwVFRWVbTNr1qwKBen0F/alS5eWLSstLa1wGlNcXJxiYmL04osvKjc3t0LW9PT0qu5umZEjR8pqteqpp56qcH3U6f0bNmyYfH199dxzz6m4uPiC39disei1117T1KlTdeutt551u6p+1pLk5eWlrKysauX4X926dVNUVJReeeWVCmNU2RG6e+65R8HBwfrLX/5Sdi3PaSdPntS4ceNkGIamTJlSbl27du3UsWNHzZ49W7Nnz1azZs00YMCAsvUuLi667rrr9PXXX59xxsfzGXOzOeM+AWiYOOIEAOfhwQcfVH5+vkaNGqW2bduqqKhIK1eu1OzZsxUZGalx48ZJOlVynnnmGU2ePFkHDx7UyJEj5ePjo4SEBM2dO1d33323Hn30UdlsNj3zzDO65557dOmll2rMmDFKSEjQ+++/X+Eap/bt26t3796aPHmyjh8/XjZ5QklJSbntrFar3n33XV1xxRVq3769xo0bp7CwMCUlJWnRokXy9fXVd999V639btWqlZ544gk9/fTT6t+/v6699lrZ7XatW7dOzZs31/Tp0+Xr66u33npLt956q7p166Ybb7xRTZs2VWJion744Qf17dtX//73v6v1viNGjNCIESPOuU1VP2vpVKmcPXu2Jk2apB49esjb21tXX311tTJZrVa99dZbuvrqq9WlSxeNGzdOzZo10+7du7Vjxw79/PPPZ31ukyZN9NVXX+nKK69Ut27ddNdddyk2NlYpKSmaNWuW9u/fr1dfffWMN78dM2aMpkyZInd3d915550VJul4/vnntWjRIvXq1UsTJkxQbGysjh8/ro0bN+rXX3/V8ePHq7Wf9YEz7hOABqiOZ/EDAKcwf/58Y/z48Ubbtm0Nb29vw83NzWjVqpXx4IMPGqmpqRW2//rrr41+/foZXl5ehpeXl9G2bVtj4sSJxp49e8pt9+abbxpRUVGG3W43unfvbixdutQYOHBguenIDcMw4uPjjSFDhhh2u90ICQkx/vrXvxoLFiyoMA20YRjGpk2bjGuvvdZo0qSJYbfbjYiICGP06NHGwoULy7Y5PR15enp6ueeeberzmTNnGl27djXsdrsREBBgDBw40FiwYEG5bRYtWmQMGzbM8PPzM9zd3Y2YmBjjjjvuMNavX3/Oz/aP05Gfy/9OR35aVT7r3Nxc4+abbzb8/f0NSWVTk5/rvc80zbZhGMby5cuNoUOHGj4+PoaXl5fRqVMn4/XXXz9n9tMSEhKMCRMmGC1btjRsNpsRFBRkXHPNNcayZcvO+px9+/YZkgxJxvLly8+4TWpqqjFx4kQjPDzcsNlsRmhoqDF48GDj7bffrrA/lX3OZ3I+05GfaawiIiKMK6+8ssJyScbEiROrvU8AUJsshlGNK34BAHVu0KBBkqTFixebmgMAgMaMa5wAAAAAoBIUJwAAAACoBMUJAAAAACrBNU4AAAAAUAmOOAEAAABAJShOAAAAAFCJRncDXIfDoeTkZPn4+MhisZgdBwAAAIBJDMNQTk6OmjdvXuGG4v+r0RWn5ORkhYeHmx0DAAAAQD1x+PBhtWjR4pzbNLri5OPjI+nUh+Pr62tyGqm4uFi//PKLLrvsMtlsNrPjoAYwps6HMXVOjKvzYUydE+PqfOrTmGZnZys8PLysI5xLoytOp0/P8/X1rTfFydPTU76+vqb/wUHNYEydD2PqnBhX58OYOifG1fnUxzGtyiU8TA4BAAAAAJWgOAEAAABAJShOAAAAAFAJihMAAAAAVILiBAAAAACVoDgBAAAAQCUoTgAAAABQCYoTAAAAAFSC4gQAAAAAlaA4AQAAAEAlKE4AAAAAUAmKEwAAAABUguIEAAAAAJWgOAEAAABAJepFcXrjjTcUGRkpd3d39erVS2vXrj3rtrNmzZLFYin34+7uXodpAQAAADQ2phen2bNna9KkSZo6dao2btyozp07a9iwYUpLSzvrc3x9fXX06NGyn0OHDtVhYgAAAACNjavZAV566SVNmDBB48aNkyTNmDFDP/zwg2bOnKnHH3/8jM+xWCwKDQ2ty5i1YtfRbO1PzdaOExYFHDgmL3e73G1W2V1d5G6zyt3mIrvrqV9tLqZ3XAAAAKDRMrU4FRUVacOGDZo8eXLZMqvVqiFDhmjVqlVnfV5ubq4iIiLkcDjUrVs3Pffcc2rfvv0Zty0sLFRhYWHZ4+zsbElScXGxiouLa2hPzs/cjYf19rKDklz09u4N59zWxWqR3dWqUF93PTw4Rpe3D5HFYqmTnKie03+uzP7zhZrDmDonxtX5MKbOiXF1PvVpTKuTwWIYhlGLWc4pOTlZYWFhWrlypfr06VO2/LHHHtOSJUu0Zs2aCs9ZtWqV9u3bp06dOikrK0svvviili5dqh07dqhFixYVtn/yySc1bdq0Css//fRTeXp61uwOVdOyFIs2ZlhV7NAZf0qMsxejWH+Hro9yqAmXdwEAAADnJT8/XzfffLOysrLk6+t7zm0bXHH6X8XFxWrXrp1uuukmPf300xXWn+mIU3h4uDIyMir9cOpCcXGxFixYoKFDh8pms5Vb53AYKip16GSxQ4UlpTpZ7NC8zcn6z7IEFZca8rBZ9adLW+mOPi3lyql89ca5xhQNE2PqnBhX58OYOifG1fnUpzHNzs5WUFBQlYqTqafqBQUFycXFRampqeWWp6amVvkaJpvNpq5du2r//v1nXG+322W328/4PLMH6o/OlscuyecPjx+93E8ju7XQX+du19qE4/rHz3v17dYUPTeqg7q2DKizvKhcffszhgvHmDonxtX5MKbOiXF1PvVhTKvz/qYepnBzc1NcXJwWLlxYtszhcGjhwoXljkCdS2lpqbZt26ZmzZrVVsx6p1Wwjz6f0FsvXNdJfh427TqarWvfWqkp32xX9knzzxUFAAAAnI3p53dNmjRJ77zzjj744APt2rVL9913n/Ly8spm2bvtttvKTR7x1FNP6ZdfftGBAwe0ceNGjR07VocOHdJdd91l1i6Ywmq1aHSPcC3880Bd2zVMhiF9uOqQhr60RPO3HZWJZ2ACAAAATsf06cjHjBmj9PR0TZkyRSkpKerSpYt++uknhYSESJISExNltf633504cUITJkxQSkqKAgICFBcXp5UrVyo2NtasXTBVkLddL43pouviWuiJudt08Fi+7vtkowa3Dda0Ee3VIsDcCTAAAAAAZ2B6cZKkBx54QA888MAZ1y1evLjc45dfflkvv/xyHaRqWPq2CtJPDw/Qm4v2660l8Vq4O00r44/pz5e10fi+UbJambocAAAAOF+mn6qHmuNuc9Gkyy7S/If6q2dkoAqKS/XMD7s0/oN1OpZbWPkLAAAAADgjipMTahXso8/v7q1nRnaQ3dWqxXvSNfy1ZVpz4JjZ0QAAAIAGieLkpKxWi8b2jtC8iX0V3dRLqdmFuumd1Xp94T6VOpg4AgAAAKgOipOTa9fMV9890E/XdguTw5D+tWCvbp+5Vmk5J82OBgAAADQYFKdGwMvuqpdGd9GLN3SWh81Fy/dnaPiry7Vif4bZ0QAAAIAGgeLUiFwf10LfPtBXF4X4KCO3UGPfW6OXftmjklKH2dEAAACAeo3i1Mi0DvHRvIl9dVPPcBmG9Npv+3Xzu2uUksWpewAAAMDZUJwaIQ83F02/tpNevbGLvNxctDbhuIa/tkyL9qSZHQ0AAAColyhOjdiILmH6/k/9FdvMV8fzijTu/XV6e2m82bEAAACAeofi1MhFBXlpzv0X67Y+EZKk6fN3c78nAAAA4H9QnCB3m4ueGtFBN8S1kGFIk77YoqyCYrNjAQAAAPUGxQllpl7TXhFNPJWUWaAn5m6TYXCjXAAAAECiOOEPvO2uemVMF7lYLfp+61HN2ZhkdiQAAACgXqA4oZyuLQP0yJDWkqQp32zXoWN5JicCAAAAzEdxQgX3DWqlnpGByisq1cOzN6uYG+QCAACgkaM4oQIXq0UvjeksH3dXbUrM1Ou/7Tc7EgAAAGAqihPOqEWAp54d1VGS9O/f9mndweMmJwIAAADMQ3HCWV3Tubmu7RYmhyE9/PlmZZ9kinIAAAA0ThQnnNO0a9qrZeCpKcqnzNtudhwAAADAFBQnnJOPu00v/z5F+bzNyZq3iSnKAQAA0PhQnFCpuIgA/enSU1OU/33edh0+nm9yIgAAAKBuUZxQJRMviVH3iADlFJbo4dmbVcIU5QAAAGhEKE6oElcXq14e00U+dldtOHRCbyyKNzsSAAAAUGcoTqiy8EBPPT2ygyTptd/2acOhEyYnAgAAAOoGxQnVMrJrmEZ2aa5Sh6GHZ29SDlOUAwAAoBGgOKHanhrZQS0CPHT4eIH+/dt+s+MAAAAAtY7ihGrzdbfpyavbS5I+XZPIUScAAAA4PYoTzsulbYMV09RLOYUlmr3usNlxAAAAgFpFccJ5sVotuqt/tCTp/RUHVcz05AAAAHBiFCect1FdwxTk7aakzAL9uO2o2XEAAACAWkNxwnlzt7no1t6RkqR3lh2QYRjmBgIAAABqCcUJF+TWPhGyu1q1PSlbqw8cNzsOAAAAUCsoTrgggV5uuqF7C0mnjjoBAAAAzojihAt2Z79oWSzSb7vTtD8tx+w4AAAAQI2jOOGCRQV5aWi7EEnSu8sSTE4DAAAA1DyKE2rEhAGnpiafsylJ6TmFJqcBAAAAahbFCTWie0SAuoT7q6jEoY9WHTQ7DgAAAFCjKE6oERaLRXf/ftTpo9WHVFBUanIiAAAAoOZQnFBjhrUPVXigh07kF+urjUfMjgMAAADUGIoTaoyL1aI7+0ZJkt5bdkClDm6ICwAAAOdAcUKNuqF7uHzdXXXwWL5+3ZVqdhwAAACgRlCcUKO87K4a2ztCkvTOUm6ICwAAAOdAcUKNu+PiSNlcLFp/6IQ2Jp4wOw4AAABwwShOqHHBvu4a0SVMkvTuMo46AQAAoOGjOKFWTOh/amryn7anKPFYvslpAAAAgAtDcUKtuCjURwPbNJXDkGauSDA7DgAAAHBBKE6oNaePOs1ed1iZ+UUmpwEAAADOH8UJtaZvqyZq18xXBcWl+mRNotlxAAAAgPNGcUKtsVgsmtD/1A1xZ608qMKSUpMTAQAAAOeH4oRadVWn5gr1dVd6TqG+2ZxsdhwAAADgvFCcUKvcXK0a1zdS0qmpyQ3DMDcQAAAAcB4oTqh1N/ZsKS83F+1NzdX6Q9wQFwAAAA0PxQm1zs/DpkFtgyVJq+OPmZwGAAAAqD6KE+pEz8hASdLag8dNTgIAAABUH8UJdaLH78Vp46ETKil1mJwGAAAAqB6KE+rERaE+8nF3VV5RqXYezTY7DgAAAFAtFCfUCRerRd0jAiRJaxM4XQ8AAAANC8UJdaZH1KnT9dZxnRMAAAAaGIoT6szpCSLWHzzB/ZwAAADQoFCcUGc6tvCTm6tVx/KKFJ+eZ3YcAAAAoMooTqgzdlcXdQn3l8TpegAAAGhYKE6oU6dP11vHBBEAAABoQChOqFOnJ4jgRrgAAABoSChOqFNxEQGyWqQjJwp0NKvA7DgAAABAlVCcUKe87a5q39xPEvdzAgAAQMNBcUKd6xHJ/ZwAAADQsFCcUOd6RgVIktYlnDA5CQAAAFA1FCfUue6/H3Hak5qjzPwik9MAAAAAlaM4oc4FedsV3dRLkrT+IEedAAAAUP9RnGCKnlznBAAAgAaE4gRTnJ4ggvs5AQAAoCGgOMEUPX+/Ee62I1nKLyoxOQ0AAABwbhQnmKJFgIdCfd1V4jC0OTHT7DgAAADAOVGcYAqLxaIeUZyuBwAAgIaB4gTT9Iz8/X5OFCcAAADUcxQnmOb0EaeNhzJVXOowOQ0AAABwdhQnmKZNsI/8PGwqKC7VjuRss+MAAAAAZ0VxgmmsVou6R/x+ul4Cp+sBAACg/qI4wVQ9mSACAAAADQDFCaY6fZ3T+oPH5XAYJqcBAAAAzoziBFN1aO4nd5tVJ/KLFZ+ea3YcAAAA4IwoTjCVm6tVXcNPXefE6XoAAACoryhOMN3p0/WYIAIAAAD1FcUJpusZ+XtxOnjC5CQAAADAmVGcYLquLf3lYrUoKbNASZkFZscBAAAAKqA4wXRedld1aO4ridP1AAAAUD9RnFAv9Ijkfk4AAACovyhOqBdOTxCxliNOAAAAqIfqRXF64403FBkZKXd3d/Xq1Utr166t0vM+//xzWSwWjRw5snYDotadPuK0Py1Xx/OKTE4DAAAAlGd6cZo9e7YmTZqkqVOnauPGjercubOGDRumtLS0cz7v4MGDevTRR9W/f/86SoraFOjlplbB3pKkdZyuBwAAgHrG9OL00ksvacKECRo3bpxiY2M1Y8YMeXp6aubMmWd9TmlpqW655RZNmzZN0dHRdZgWten0UScmiAAAAEB942rmmxcVFWnDhg2aPHly2TKr1aohQ4Zo1apVZ33eU089peDgYN15551atmzZOd+jsLBQhYWFZY+zs7MlScXFxSouLr7APbhwpzPUhyxmiwv31WdrpbUJxxr058GYOh/G1Dkxrs6HMXVOjKvzqU9jWp0MphanjIwMlZaWKiQkpNzykJAQ7d69+4zPWb58ud577z1t3ry5Su8xffp0TZs2rcLyX375RZ6entXOXFsWLFhgdgTT5RRKkqu2J2Vp7nc/yu5idqILw5g6H8bUOTGuzocxdU6Mq/OpD2Oan59f5W1NLU7VlZOTo1tvvVXvvPOOgoKCqvScyZMna9KkSWWPs7OzFR4erssuu0y+vr61FbXKiouLtWDBAg0dOlQ2m83sOKZ7O36pjmadVHBsL/WNaWJ2nPPCmDofxtQ5Ma7OhzF1Toyr86lPY3r6bLSqMLU4BQUFycXFRampqeWWp6amKjQ0tML28fHxOnjwoK6++uqyZQ6HQ5Lk6uqqPXv2KCYmptxz7Ha77HZ7hdey2WymD9Qf1bc8ZukVFah5m5O18XC2BrWt+GegIWFMnQ9j6pwYV+fDmDonxtX51Icxrc77mzo5hJubm+Li4rRw4cKyZQ6HQwsXLlSfPn0qbN+2bVtt27ZNmzdvLvu55pprdMkll2jz5s0KDw+vy/ioBafv58QEEQAAAKhPTD9Vb9KkSbr99tvVvXt39ezZU6+88ory8vI0btw4SdJtt92msLAwTZ8+Xe7u7urQoUO55/v7+0tSheVomHr+PrPepsMnVFTikJur6RM/AgAAAOYXpzFjxig9PV1TpkxRSkqKunTpop9++qlswojExERZrXx5bixaBXsrwNOmE/nF2p6cpW4tA8yOBAAAAJhfnCTpgQce0AMPPHDGdYsXLz7nc2fNmlXzgWAai8Wi7pGBWrAzVesSjlOcAAAAUC9wKAf1zunT9dYd5DonAAAA1A8UJ9Q7pyeIWJtwXCeLS01OAwAAAFCcUA91aO6rZn7uyj5Zoi/XHzY7DgAAAEBxQv3j6mLVfYNO3Y/rzcXxKizhqBMAAADMRXFCvTS6e7hCfO06mnVSX204YnYcAAAANHIUJ9RL7jYX3Tvw96NOi+JVVOIwOREAAAAaM4oT6q2berZUkLddSZkFmruJo04AAAAwD8UJ9dapo07RkqR/L9qv4lKOOgEAAMAcFCfUa7f0ilCQt5sOHy/QvE1JZscBAABAI0VxQr3m4eaiCf1PHXV6Y9F+lXDUCQAAACagOKHeG9s7QgGeNh08lq/vtiabHQcAAACNEMUJ9Z6X3VV3/X7U6fXf9qvUYZicCAAAAI0NxQkNwu0XR8rf06YD6Xn6YdtRs+MAAACgkaE4oUHwtrvqzr5RkqTXF+6Tg6NOAAAAqEMUJzQYt/eNlI+7q/al5Wr+9hSz4wAAAKARoTihwfB1t2n86aNOv3HUCQAAAHWH4oQGZXzfKPnYXbU7JUe/7Ew1Ow4AAAAaCYoTGhQ/T5vu6BspSXpt4T4ZBkedAAAAUPsoTmhwxveNkpebi3Yezdavu9LMjgMAAIBGgOKEBifAy023XRwpiaNOAAAAqBsUJzRIE/pHy9PNRduSsrR4T7rZcQAAAODkKE5okAK93HRr7whJ0qscdQIAAEAtozihwbqrf7TcbVZtPpyppfsyzI4DAAAAJ0ZxQoPV1MeuW3r9ftTp170cdQIAAECtoTihQbtnQLTsrlZtTMzUyvhjZscBAACAk6I4oUEL9nXXTT1bSpLeXLzf5DQAAABwVhQnNHgTBkTLapFW7D+m+PRcs+MAAADACVGc0OCF+Xvo0rYhkqRPVieanAYAAADOiOIEpzC296nT9b7acFgFRaUmpwEAAICzoTjBKQxo3VQtAz2VfbJE321JNjsOAAAAnAzFCU7BarXo5l6njjp9vOaQyWkAAADgbChOcBo3xLWQm4tVW49kaeuRTLPjAAAAwIlQnOA0mnjbNbxjqCTp49UcdQIAAEDNoTjBqYztHSFJ+nZLsrLyi01OAwAAAGdBcYJTiYsIUNtQH50sdujrjUfMjgMAAAAnQXGCU7FYLGVHnT5ec0iGYZicCAAAAM6A4gSnM7JrmLzcXHQgPU+r4o+ZHQcAAABOgOIEp+Ntd9WobmGSmJocAAAANYPiBKd0+nS9X3akKi37pMlpAAAA0NBRnOCU2ob6qntEgEochj5fd9jsOAAAAGjgKE5wWqePOn22NlElpQ6T0wAAAKAhozjBaV3RMVSBXm46mnVSC3enmR0HAAAADRjFCU7L7uqi0d3DJUkfr2aSCAAAAJw/ihOc2i29WspikZbty9DBjDyz4wAAAKCBojjBqYUHempgm6aSpE/XJpqcBgAAAA0VxQlOb2yvU5NEfLn+sE4Wl5qcBgAAAA0RxQlO75K2wQrz99CJ/GL9uO2o2XEAAADQAFGc4PRcrBbd3KulJCaJAAAAwPmhOKFRGN09XDYXizYmZmpHcpbZcQAAANDAUJzQKDT1sWtY+1BJ0sermSQCAAAA1UNxQqMxtvepSSK+2ZyknJPFJqcBAABAQ0JxQqPRKypQrYO9lV9UqrmbksyOAwAAgAaE4oRGw2Kx6JY/TBJhGIbJiQAAANBQUJzQqFwb10IeNhftTc3Voj1pZscBAABAA0FxQqPi627TdXFhkqR7PtqgD1Ye5MgTAAAAKkVxQqMz+Yp2urJTMxWXGpr67Q49PHuz8otKzI4FAACAeozihEbHy+6qf9/UVX+7sp1crBZ9szlZo95YqQPpuWZHAwAAQD1FcUKjZLFYdFf/aH02obea+ti1JzVHI/69Qj9tTzE7GgAAAOohihMatZ5RgfrhwX7qGRmonMIS3fvxBk2fv0slpQ6zowEAAKAeoTih0Qv2ddcnE3rprn5RkqT/LDmgW99bq/ScQpOTAQAAoL6gOAGSbC5W/e2qWL1xczd5ublo1YFjuur1Zdpw6ITZ0QAAAFAPUJyAP7iyUzN980BftQr2Vmp2ocb8Z5VmrUhgynIAAIBG7oKK08mTJ2sqB1BvtAr20TcT++rKTs1U4jD05Hc79fDszTpZXGp2NAAAAJik2sXJ4XDo6aefVlhYmLy9vXXgwAFJ0t///ne99957NR4QMMPpKcv/flWsXH+fsvzGt1crI5frngAAABqjahenZ555RrNmzdILL7wgNze3suUdOnTQu+++W6PhADNZLBbd2S9KH9/VS/6eNm0+nKlRb67Q/rQcs6MBAACgjlW7OH344Yd6++23dcstt8jFxaVseefOnbV79+4aDQfUB72jm2jOfRcroomnDh8v0LVvrtTK+AyzYwEAAKAOVbs4JSUlqVWrVhWWOxwOFRcX10gooL6Jbuqtuff3VVxEgLJPluj2mWv11YYjZscCAABAHal2cYqNjdWyZcsqLP/qq6/UtWvXGgkF1EeBXm765K5euqpTMxWXGnr0yy16acFeZtwDAABoBFyr+4QpU6bo9ttvV1JSkhwOh+bMmaM9e/boww8/1Pfff18bGYF6w93motdu7KqIJp56Y1G8Xlu4T4nH8vSP6zvJ7upS+QsAAACgQar2EacRI0bou+++06+//iovLy9NmTJFu3bt0nfffaehQ4fWRkagXrFaLfrLsLb6x3Ud5Wq1aN7mZN363lpl5heZHQ0AAAC1pNpHnCSpf//+WrBgQU1nARqUMT1aKszfU/d9vEFrE47r2jdXauYdPRTm51b5kwEAANCgXNANcIHGrl/rIH19/8UK8/fQgYw8XfvWSm1MzDQ7FgAAAGpYtYuT1WqVi4vLWX+AxqZNiI/mTrxYnVr46XhekW59f70WJlm09uBxncjj9D0AAABnUO1T9ebOnVvucXFxsTZt2qQPPvhA06ZNq7FgQEMS7OOuz+/urYc+36wFO1P1baKLvn1vvSSpqY9dbUK81SbE5/cfb7UO8ZGvu83k1AAAAKiqahenESNGVFh2/fXXq3379po9e7buvPPOGgkGNDSebq6aMTZO7y2L17xVu5QtTx3JPKn0nEKl5xRqxf5j5bZv5ueu1iE+uijEW2N6tFSrYG+TkgMAAKAy5zU5xJn07t1bd999d029HNAguVgtGndxhEIyd2j48AEqcli0Ly1Xe1NztDclR3vTcrUvNUdHs06W/Szdm65P1yTq9Zu76tK2IWbvAgAAAM6gRopTQUGBXnvtNYWFhdXEywFOw8vuqi7h/uoS7l9ueVZBsfan5Whvaq7mbkrS2oTjuuuD9XriyliN7xspi8ViTmAAAACcUbWLU0BAQLkvdYZhKCcnR56envr4449rNBzgrPw8bIqLCFRcRKCuj2uhKd9s12drD+vp73cqPj1X065pL5sLk14CAADUF9UuTi+//HK54mS1WtW0aVP16tVLAQEBNRoOaAxsLlY9N6qjYpp669kfd+nTNYlKPJavN27pJj8PJpAAAACoD6pdnO64445aiAE0bhaLRXf1j1ZkEy/96fNNWr4/Q9e+uUIz7+ihiCZeZscDAABo9KpUnLZu3VrlF+zUqdN5hwEauyGxIfry3j6664P1ik/P08g3Vug/t3ZXz6hAs6MBAAA0alUqTl26dJHFYpFhGOfczmKxqLS0tEaCAY1V++Z++mZiX9314XptPZKlW95dreev7aTr4lqYHQ0AAKDRqlJxSkhIqO0cAP4g2Ndds+/uoz9/uVk/bkvRn7/cogMZufrz0ItktTLjHgAAQF2rUnGKiIio7RwA/oeHm4v+fVM3vRS0V/9etF9vLIrXgfQ8vTS6izzcXMyOBwAA0Kic932cdu7cqcTERBUVFZVbfs0111xwKACnWK0WPTrsIkUFeenxOVs1f3uKkjJXada4ngr0cjM7HgAAQKNR7eJ04MABjRo1Stu2bSt33dPpKcq5xgmoedfFtVB4oKfu+ejUdU8vLdijZ0Z2NDsWAABAo1HtO2w+9NBDioqKUlpamjw9PbVjxw4tXbpU3bt31+LFi2shIgBJ6hkVqDdviZMkfbH+iNKyT5qcCAAAoPGodnFatWqVnnrqKQUFBclqtcpqtapfv36aPn26/vSnP9VGRgC/6x0dqO4RASoqceidZQfMjgMAANBoVLs4lZaWysfHR5IUFBSk5ORkSacmkNizZ895hXjjjTcUGRkpd3d39erVS2vXrj3rtnPmzFH37t3l7+8vLy8vdenSRR999NF5vS/Q0FgsFk28tJUk6ePViTqeV1TJMwAAAFATql2cOnTooC1btkiSevXqpRdeeEErVqzQU089pejo6GoHmD17tiZNmqSpU6dq48aN6ty5s4YNG6a0tLQzbh8YGKgnnnhCq1at0tatWzVu3DiNGzdOP//8c7XfG2iIBrVpqg5hviooLtX7K7hVAAAAQF2odnH629/+JofDIUl66qmnlJCQoP79++vHH3/Ua6+9Vu0AL730kiZMmKBx48YpNjZWM2bMkKenp2bOnHnG7QcNGqRRo0apXbt2iomJ0UMPPaROnTpp+fLl1X5voCGyWCyaOOjUUadZKw8q+2SxyYkAAACcX5Vn1evevbvuuusu3XzzzfL19ZUktWrVSrt379bx48cVEBBQNrNeVRUVFWnDhg2aPHly2TKr1aohQ4Zo1apVlT7fMAz99ttv2rNnj/7xj3+ccZvCwkIVFhaWPc7OzpYkFRcXq7jY/C+cpzPUhyyoGXUxppe2aaKYpl6KT8/TB8sP6N6B1T/ai6rj76lzYlydD2PqnBhX51OfxrQ6GSzG6fnEK3HnnXfqyy+/VGlpqa677jqNHz9egwYNOt+MkqTk5GSFhYVp5cqV6tOnT9nyxx57TEuWLNGaNWvO+LysrCyFhYWpsLBQLi4uevPNNzV+/Pgzbvvkk09q2rRpFZZ/+umn8vT0vKD8gJnWpVv08X4XebsamtqtVNwTFwAAoHry8/N18803Kysrq+zg0NlU+YjTe++9p9dff11ffPGFZs2apcGDBysqKkrjx4/X7bffrrCwsAsOXlU+Pj7avHmzcnNztXDhQk2aNEnR0dFnLHKTJ0/WpEmTyh5nZ2crPDxcl112WaUfTl0oLi7WggULNHToUNlsNrPjoAbU1ZheVurQkldX6PCJAmUGtdcdfSJq7b0aO/6eOifG1fkwps6JcXU+9WlMT5+NVhXVugGup6en7rjjDt1xxx2Kj4/X+++/r//85z+aOnWqLrvsMt1555269tprq/x6QUFBcnFxUWpqarnlqampCg0NPevzrFarWrU6dY1Hly5dtGvXLk2fPv2Mxclut8tut1dYbrPZTB+oP6pveXDhantMbTbpvkGt9Ne52/Te8kO67eIo2V057FSb+HvqnBhX58OYOifG1fnUhzGtzvtXe3KI02JiYvTMM8/o4MGD+uyzz7R69WrdcMMN1XoNNzc3xcXFaeHChWXLHA6HFi5cWO7Uvco4HI5y1zEBjcV1cWEK9XVXSvZJfb0hyew4AAAATuu8i5MkLV68uOwIVGlpqSZMmFDt15g0aZLeeecdffDBB9q1a5fuu+8+5eXlady4cZKk2267rdzkEdOnT9eCBQt04MAB7dq1S//617/00UcfaezYsReyK0CDZHd10YQBpyaGmLEkXiWlDpMTAQAAOKdqnaonSUeOHNGsWbM0a9YsHThwQP3799ebb76pG264QR4eHtUOMGbMGKWnp2vKlClKSUlRly5d9NNPPykkJESSlJiYKKv1v/0uLy9P999/v44cOSIPDw+1bdtWH3/8scaMGVPt9wacwU09w/XGov1KPJ6v77Yma1TXFmZHAgAAcDpVLk5ffPGFZs6cqYULFyo4OFi33367xo8fX3at0YV44IEH9MADD5xx3eLFi8s9fuaZZ/TMM89c8HsCzsLTzVV39ovSP3/eozcXxWtE5zBZrdW7NQAAAADOrcqn6o0dO1YeHh6aO3euDh8+rOeee65GShOAC3drnwj5uLtqX1quftmZYnYcAAAAp1PlI05HjhxRcHBwbWYBcJ583W264+JIvf7bfv170X4Nax9a7RtSAwAA4OyqfMSJ0gTUb+P6RsnD5qLtSdlavDfd7DgAAABO5YJm1QNQfwR6uemWXi0lSW/8tl+GYZicCAAAwHlQnAAnMmFAtNxcrFp/6ITWJBw3Ow4AAIDToDgBTiTE1103dD81Hfkbi/abnAYAAMB5VLs4rVu3TmvWrKmwfM2aNVq/fn2NhAJw/u4dGCMXq0XL9mVoy+FMs+MAAAA4hWoXp4kTJ+rw4cMVliclJWnixIk1EgrA+QsP9NTILmGSpH9z1AkAAKBGVLs47dy5U926dauwvGvXrtq5c2eNhAJwYe6/JEYWi7RgZ6p2p2SbHQcAAKDBq3ZxstvtSk1NrbD86NGjcnWt8m2hANSimKbeGt6hmSTpjUXxJqcBAABo+KpdnC677DJNnjxZWVlZZcsyMzP117/+VUOHDq3RcADO3/2XxEiSftiarMV70kxOAwAA0LBVuzi9+OKLOnz4sCIiInTJJZfokksuUVRUlFJSUvSvf/2rNjICOA/tm/vp2m5hchjS3R9t0LJ93BQXAADgfFW7OIWFhWnr1q164YUXFBsbq7i4OL366qvatm2bwsPDayMjgPP0/LWdNDQ2REUlDt31wXqt2J9hdiQAAIAG6bwuSvLy8tLdd99d01kA1DA3V6veuLmb7vt4gxbuTtOdH6zT+3f0VJ+YJmZHAwAAaFCqVJy+/fZbXXHFFbLZbPr222/Pue0111xTI8EA1Aw3V6veHNtN9360QYv2pGv8rHX6YHxP9YwKNDsaAABAg1Gl4jRy5EilpKQoODhYI0eOPOt2FotFpaWlNZUNQA2xu7rorbFxuvujDVq6N113vL9WH47vqe6RlCcAAICqqNI1Tg6HQ8HBwWW/P9sPpQmov9xtLnr71jj1axWk/KJS3T5zrTYcOmF2LAAAgAahWpNDFBcXa/Dgwdq3b19t5QFQi9xtLnrntu7qE91EeUWlumPmWm0+nGl2LAAAgHqvWsXJZrNp69attZUFQB3wcHPRe3d0V6+oQOUUlujW99Zo65FMs2MBAADUa9Wejnzs2LF67733aiMLgDri6eaqmXf0UI/IAOWcLNHYd9doe1JW5U8EAABopKo9HXlJSYlmzpypX3/9VXFxcfLy8iq3/qWXXqqxcABqj5fdVe+P61l2rdMt767RpxN6qX1zP7OjAQAA1DvVLk7bt29Xt27dJEl79+6t8UAA6o633VWzxvXQre+dutZp7Ltr9OmE3mrXzNfsaAAAAPVKtYvTokWLaiMHAJP4uNv04Z09deu7a7TlSJaufXOl/jS4te7sFyU312qfzQsAAOCUqv2taPz48crJyamwPC8vT+PHj6+RUADqlq+7TR+O76Xe0YEqKC7VP37areGvLdOq+GNmRwMAAKgXql2cPvjgAxUUFFRYXlBQoA8//LBGQgGoe36eNn02obdevKGzmni5aX9arm56Z7Uemb1ZaTknzY4HAABgqioXp+zsbGVlZckwDOXk5Cg7O7vs58SJE/rxxx/LbpILoGGyWCy6Pq6FfvvzII3t3VIWizR3U5IG/2uJPlh5UKUOw+yIAAAApqjyNU7+/v6yWCyyWCxq06ZNhfUWi0XTpk2r0XAAzOHnadMzIzvqhrhw/W3edm1LytLUb3foyw2H9fSIDuraMsDsiAAAAHWqysVp0aJFMgxDl156qb7++msFBgaWrXNzc1NERISaN29eKyEBmKNzuL/mTeyrT9cm6oWfdmt7UraufWulbuzRUv93+UXy93QzOyIAAECdqHJxGjhwoCQpISFBLVu2lMViqbVQAOoPF6tFt/aO0OXtQzV9/i7N2Zikz9Ym6ucdKXr8ira6vlsLWa389wAAADi3ak8OERERoeXLl2vs2LG6+OKLlZSUJEn66KOPtHz58hoPCKB+aOpj10uju+jzu3urdbC3jucV6bGvtuqWd9coKbPihDEAAADOpNrF6euvv9awYcPk4eGhjRs3qrCwUJKUlZWl5557rsYDAqhfekc30Y8P9ddfh7eVh81Fqw4c0+UvL9XcTUdkGEweAQAAnFO1i9MzzzyjGTNm6J133pHNZitb3rdvX23cuLFGwwGon2wuVt09IEY/PtRfXcL9lVNYokdmb9HETzfqRF6R2fEAAABqXLWL0549ezRgwIAKy/38/JSZmVkTmQA0EFFBXvrq3j6aNLSNXK0W/bgtRcNeWarFe9LMjgYAAFCjql2cQkNDtX///grLly9frujo6BoJBaDhcHWx6k+DW2vO/RcrpqmX0nIKdcf76/S3eduUX1RidjwAAIAaUe3iNGHCBD300ENas2aNLBaLkpOT9cknn+jRRx/VfffdVxsZATQAnVr464c/9dcdF0dKkj5enagrX1uuTYknzA0GAABQA6o8Hflpjz/+uBwOhwYPHqz8/HwNGDBAdrtdjz76qB588MHayAiggXC3uejJa9prSLsQPfrlFiVk5On6Gas0cVCMHhzcWjaXav9bTa1YFX9Mn61NVEQTT43oEqZWwd5mRwIAAPVctYuTxWLRE088ob/85S/av3+/cnNzFRsbK29vvngAOKVf6yD9/PAATfl2u77ZnKzXftuvRXvS9fKYLqaWlKyCYk3/cZc+X3e4bNnrv+1XhzBfjewSpqs7N1eIr7tp+QAAQP1V7eJ0mpubm2JjY2syCwAn4udp06s3dtWQdiH627zt2paUpStfW6ZnRnbQDd3D6zzPT9uP6u/f7FB6zqlbKFzXrYVO5Bdp6d50bU/K1vakbD374y5dHNNEIzqH6fKOofJ1t1XyqgAAoLGocnEaP358lbabOXPmeYcB4Hyu7txcPSID9ZevtmjZvgz95aut2nokS3+/KlZurrV/6l5q9klN/WaHftqRIkmKDvLS89d1Us+oQEnS8bwi/bA1WfM2J2vDoRNasf+YVuw/pr99s12D2wZrRJcw9YsJqPWcAACgfqtycZo1a5YiIiLUtWtXbnIJoFpC/dz1wbieev23/Xr51736aPUh7TqarTdv6abgWjo1zjAMfb7usJ77cZdyTpbI1WrRvQNj9MClreRucynbLtDLTbf2idStfSJ1+Hi+vt2SrHmbkrQvLVfzt6do/vYU+bq7qoOfVX0LihVk4ygUAACNUZWL03333afPPvtMCQkJGjdunMaOHavAwMDazAbAiVitFj00pLU6hPnq4c83a/2hE7rq9eV6a2yc4iJq9ohOQkaeJs/ZqtUHjkuSOrXw0/PXdlJsc99zPi880FMTL2ml+wfFaOfRbH2zOVnfbk5WSvZJrTxp1V0fbdSnE3rL0+28z3IGAAANVJXPk3njjTd09OhRPfbYY/ruu+8UHh6u0aNH6+eff+YIFIAqG9wuRN8+2E+tg72VllOoG99epU/WHKqR/44Ulzr01uJ4Xf7KUq0+cFweNhf97cp2mnt/30pL0x9ZLBa1b+6nvw5vpxWPX6qZt3WTp4uhzYezdM9HG1RU4rjgrAAAoGGp1gUGdrtdN910kxYsWKCdO3eqffv2uv/++xUZGanc3NzaygjAyUQFeWnexL4a3jFUxaWGnpi7XY9/vU0ni0vP+zU3H87UyDdW6B8/7VZhiUP9Wwfpl0cG6K7+0XKxWs77dV2sFvVvHaS725XKw2bVsn0ZmvTFZpU6+AcjAAAak/M+38RqtcpiscgwDJWWnv+XHQCNk5fdVW/c3E0zlhzQP3/erdnrD2t3SrbeGhun5v4elT6/pNShDYdO6Nddqfp1V5oSMvIkSX4eNv39qlhd1y1MFsv5F6b/FeUjvXFTF93zySZ9v/Wo/DxsemZkhxp9DwAAUH9V64hTYWGhPvvsMw0dOlRt2rTRtm3b9O9//1uJiYncxwlAtVksFt03KEazxvWUv6dNW45k6erXl2v1gWNn3D63sEQ/bjuqSbM3q/uzv2rM26v1zrIEJWTkyeZi0aiuYfp10kBdH9eiVgpN/9ZBeml0F1ks0idrEvWvX/bW+HsAAID6qcpHnO6//359/vnnCg8P1/jx4/XZZ58pKCioNrMBaCQGtGmq7x7op7s/2qBdR7N1y7tr9Lcr2+mOiyN1NOukFu5K1YJdaVodf0xFpf+9vsjf06ZL2wZrSLsQ9W8dJJ86uO/S1Z2bK/tksZ6Yu13/XrRf/p423dU/utbfFwAAmKvKxWnGjBlq2bKloqOjtWTJEi1ZsuSM282ZM6fGwgFoPMIDPTXnvos1ec5WzducrGnf7dR7yxN05ERBue2igrw0NDZEQ9qFqFtLf7m61P69oP7XLb0ilJlfrH/+vEfP/LBLAZ5uui6uRZ3nAAAAdafKxem2227jXH4AtcrDzUUvj+miji389dyPu3TkRIGsFikuIkBD2oVoSGyIYprWj9OC7x8UoxN5RXp3eYIe+3qrfD1sGhobYnYsAABQS6p1A1wAqG0Wi0V39otSj8gAJWTkqV+rIDXxtpsdqwKLxaK/Dm+nE/nF+nrjEU38dKM+HN9TvaObmB0NAADUgro/xwUAqqBTC3+N6BJWL0vTaVarRf+4rqOGxoaoqMShuz5Yr+1JWWbHAgAAtYDiBAAXwNXFqtdv6qre0YHKLSzR7TPX6kA697UDAMDZUJwA4AK521z0zm3d1SHMV8fyinTre2t1NKug8icCAIAGg+IEADXAx92mWeN6KjrIS0mZBbrtvbU6WczNwQEAcBYUJwCoIUHedn10Vy8FebtpX1quftmZanYkAABQQyhOAFCDwvw9dHPPlpKkL9cfNjkNAACoKRQnAKhh18eFS5KW789QUibXOgEA4AwoTgBQw1o28VSf6CYyDOnrDUfMjgMAAGoAxQkAasHoHi0kSV9uOCyHwzA5DQAAuFAUJwCoBZe3byYfu6sOHy/QmoTjZscBAAAXiOIEALXAw81FV3VuLolJIgAAcAYUJwCoJaO7nzpd78ftR5V9stjkNAAA4EJQnACglnQJ91erYG+dLHboh61HzY4DAAAuAMUJAGqJxWIpO+r0BafrAQDQoFGcAKAWjeraQi5WizYlZmpfao7ZcQAAwHmiOAFALWrqY9clFwVLkr7knk4AADRYFCcAqGWnT9ebszFJxaUOk9MAAIDzQXECgFp2SdtgBXm7KSO3UIv3pJsdBwAAnAeKEwDUMpuLVaO6hklikggAABoqihMA1IEbuodLkhbtTlN6TqHJaQAAQHVRnACgDrQJ8VGXcH+VOAzN25RkdhwAAFBNFCcAqCOjfz/q9MX6wzIMw+Q0AACgOihOAFBHrurcTO42q/al5WrLkSyz4wAAgGqgOAFAHfF1t+mKDs0kMUkEAAANDcUJAOrQDb/f0+m7zckqKCo1OQ0AAKgqihMA1KHeUU3UIsBDOYUl+nlHitlxAABAFVGcAKAOWa0W3RD330kiAABAw0BxAoA6dl1cmCwWaWX8MR0+nm92HAAAUAUUJwCoYy0CPNU3JkiS9OWGIyanAQAAVUFxAgATnJ4k4usNR+RwcE8nAADqO4oTAJhgWPtQ+bq7KimzQCvjj5kdBwAAVILiBAAmcLe5aESXMElMEgEAQENAcQIAk5w+Xe+nHSnKyi82OQ0AADgXihMAmKRjmJ/ahvqoqMShb7cmmx0HAACcA8UJAExisVh0Q/dT93T6ktP1AACo1yhOAGCikV2ay9Vq0dYjWdqbmmN2HAAAcBYUJwAwURNvuy5pGyzp1NTkAACgfqI4AYDJrut2apKIuZuSVFLqMDkNAAA4E4oTAJjs0rbBCvC0KS2nUMv3Z5gdBwAAnAHFCQBM5uZqLbun09cbk0xOAwAAzqReFKc33nhDkZGRcnd3V69evbR27dqzbvvOO++of//+CggIUEBAgIYMGXLO7QGgITh9ut7PO1KUVcA9nQAAqG9ML06zZ8/WpEmTNHXqVG3cuFGdO3fWsGHDlJaWdsbtFy9erJtuukmLFi3SqlWrFB4erssuu0xJSfwrLYCGq0OYr9qEeKuoxKEfth41Ow4AAPgfrmYHeOmllzRhwgSNGzdOkjRjxgz98MMPmjlzph5//PEK23/yySflHr/77rv6+uuvtXDhQt12220Vti8sLFRhYWHZ4+zsbElScXGxiovN/1fd0xnqQxbUDMbU+dTVmI7s0kwv/LxPX204rBu6NavV9wJ/V50RY+qcGFfnU5/GtDoZLIZhGLWY5ZyKiork6empr776SiNHjixbfvvttyszM1PffPNNpa+Rk5Oj4OBgffnll7rqqqsqrH/yySc1bdq0Css//fRTeXp6XlB+AKhJWUXS1A0uMmTRE11KFOxhdiIAAJxbfn6+br75ZmVlZcnX1/ec25p6xCkjI0OlpaUKCQkptzwkJES7d++u0mv83//9n5o3b64hQ4accf3kyZM1adKkssfZ2dllp/dV9uHUheLiYi1YsEBDhw6VzWYzOw5qAGPqfOpyTBdmb9SSfRk64ddGdwxpVavv1djxd9X5MKbOiXF1PvVpTE+fjVYVpp+qdyGef/55ff7551q8eLHc3d3PuI3dbpfdbq+w3GazmT5Qf1Tf8uDCMabOpy7G9Pru4VqyL0PfbDmqR4e1ldVqqdX3A39XnRFj6pwYV+dTH8a0Ou9v6uQQQUFBcnFxUWpqarnlqampCg0NPedzX3zxRT3//PP65Zdf1KlTp9qMCQB1ZmhsiHzcXZWUWaDVB46ZHQcAAPzO1OLk5uamuLg4LVy4sGyZw+HQwoUL1adPn7M+74UXXtDTTz+tn376Sd27d6+LqABQJ9xtLrq6c3NJ0lcbj5icBgAAnGb6dOSTJk3SO++8ow8++EC7du3Sfffdp7y8vLJZ9m677TZNnjy5bPt//OMf+vvf/66ZM2cqMjJSKSkpSklJUW5urlm7AAA16vQ9nX7anqK8whKT0wAAAKkeXOM0ZswYpaena8qUKUpJSVGXLl30008/lU0YkZiYKKv1v/3urbfeUlFRka6//vpyrzN16lQ9+eSTdRkdAGpFt5b+igryUkJGnn7cdlQ3dA83OxIAAI2e6cVJkh544AE98MADZ1y3ePHico8PHjxY+4EAwEQWi0XXx7XQP3/eo683HqE4AQBQD5h+qh4AoKJRXcNksUirDxzX4eP5ZscBAKDRozgBQD3U3N9DF8c0kSTN3ZRkchoAAEBxAoB66vQkEV9vPCLDMExOAwBA40ZxAoB66vIOofJyc9GhY/laf+iE2XEAAGjUKE4AUE95urlqeMdmkqSvN3BPJwAAzERxAoB67Lq4U6fr/bD1qAqKSk1OAwBA40VxAoB6rGdkoFoEeCinsES/7EwxOw4AAI0WxQkA6jGr1VI2ScRXnK4HAIBpKE4AUM+dLk4r9mcoJeukyWkAAGicKE4AUM+1bOKpnpGBchjc0wkAALNQnACgAbguLkyS9NWGw9zTCQAAE1CcAKABGN6xmdxtVsWn52nLkSyz4wAA0OhQnACgAfBxt+ny9qGSuKcTAABmoDgBQANx+p5O325JVmEJ93QCAKAuUZwAoIG4OCZIob7uyioo1ocrD6moxGF2JAAAGg2KEwA0EC5Wi67//ajTsz/uUs/nftVf527T2oTjcjiYMAIAgNrkanYAAEDVPTi4lYpKHZq7KUnpOYX6dE2iPl2TqDB/D13TpblGdgnTRaE+ZscEAMDpUJwAoAGxu7ror8Pb6f8ub6tV8cc0b3OSftqeoqTMAr21OF5vLY5X21Afjewapms6N1dzfw+zIwMA4BQoTgDQALlYLerXOkj9WgfpmZEdtHBXmuZtTtLiPWnanZKj5+fv1vPzd6tnVKCu7tRM7Zr5KrqptwK93MyODgBAg0RxAoAGzt3mois7NdOVnZopM79I87enaN6mJK1JOK61v/+c5u9pU3SQl6KbeisqyEsxTU/9PqKJp+yuLibuBQAA9RvFCQCciL+nm27q2VI39Wyp5MwCfbslWSv2Z+hAep6SMguUmV+sjYmZ2piYWe55VovUIsBT0U29NLhdiMb2aimLxWLOTgAAUA9RnADASTX399C9A2N078AYSVJBUakSMvJ0ICNXB9LzdCA9Vwcy8nQgPU+5hSVKPJ6vxOP5WrwnXXZXq0Z3Dzd5DwAAqD8oTgDQSHi4uSi2ua9im/uWW24YhtJzC3UgPU8/bjuqD1cd0rRvd6hPdBOFB3qalBYAgPqF+zgBQCNnsVgU7OOu3tFNNPXq9uoZGai8olI9MnuzSrk/FAAAkihOAIA/cLFa9K/RneVtd9X6Qyf0n6XxZkcCAKBeoDgBAMoJD/TU1KtjJUkvL9ir7UlZJicCAMB8FCcAQAXXx7XQsPYhKi419MjszTpZXGp2JAAATEVxAgBUYLFY9NyojgrytmtfWq7++fMesyMBAGAqihMA4IyaeNv1wvUdJUnvLU/Qiv0ZJicCAMA8FCcAwFld2jZEN/dqKUl69MstysovNjkRAADmoDgBAM7pb1e2U2QTTx3NOqkp3243Ow4AAKagOAEAzsnTzVUvj+kiF6tF32xO1rdbks2OBABAnaM4AQAq1bVlgCZe0kqS9Le525SSddLkRAAA1C2KEwCgSh68tJU6tfBT9skS/eWrLXI4DLMjAQBQZyhOAIAqsblY9fKYLnK3WbVsX4Y+XHXQ7EgAANQZihMAoMpimnrrr8PbSZKmz9+tfak5JicCAKBuUJwAANVya+8IDWjTVIUlDj3yxWYVlTjMjgQAQK2jOAEAqsViseif13eSv6dN25Oy9fpv+8yOBABAraM4AQCqLcTXXc+O7ChJenvpAaXnFJqcCACA2kVxAgCcl+EdQ9U53F+FJQ7NXJFgdhwAAGoVxQkAcF4sFosmDoqRJH286pCyTxabnAgAgNpDcQIAnLch7ULUOthbOYUl+mjVIbPjAABQayhOAIDzZrVadN/vR53eX5Ggk8WlJicCAKB2UJwAABfk6s7NFebvoYzcIn2x/rDZcQAAqBUUJwDABbG5WHXPwGhJ0n+WHFBxKfd1AgA4H4oTAOCCje4eriBvNyVlFujbzclmxwEAoMZRnAAAF8zd5qLx/aIkSW8tiZfDYZicCACAmkVxAgDUiLG9I+Rjd9X+tFwt2JVqdhwAAGoUxQkAUCN83W26tU+EJOnNxfEyDI46AQCcB8UJAFBjxveLkt3Vqi2HM7Uq/pjZcQAAqDEUJwBAjQnytmtMj3BJ0huL95ucBgCAmkNxAgDUqLsHRMvVatGK/ce05XCm2XEAAKgRFCcAQI1qEeCpa7o0lyS9yVEnAICToDgBAGrcfQNjJEk/70jV/rQck9MAAHDhKE4AgBrXOsRHl8WGSJLeWnzA5DQAAFw4ihMAoFbcf0krSdI3m5N05ES+yWkAALgwFCcAQK3oEu6vi2OaqMRh6J2lHHUCADRsFCcAQK2Z+PtRp8/XHVZGbqHJaQAAOH8UJwBArbk4pok6t/BTYYlD769IMDsOAADnjeIEAKg1FotF9w06ddTpw1WHlHOy2OREAACcH4oTAKBWXRYbolbB3so5WaKPVyeaHQcAgPNCcQIA1Cqr1aJ7f7+v03vLD+hkcanJiQAAqD6KEwCg1o3o0lxh/h7KyC3SMz/spDwBABocihMAoNbZXKx6aHBrSdLHqxN12ctLtWxfusmpAACoOlezAwAAGofRPcLl52nT1G92KPF4vm59b61GdGmuv10Zq6Y+9jrLcbK4VAt2puqn7UeVlWaVx5509W8TIg83lzrLAABoeChOAIA6M6x9qPq2CtK/ftmjD1Ye1Debk7Vod5omD2+nMd3DZbVaauV9DcPQxsQT+mpDkr7fmqyckyW/r7Fq+ceb5OZqVe/oJrrkoqa65KJgRQZ51UoOAEDDRXECANQpb7urpl7dXqO6hmnynG3akZytyXO2ac7GI3puVEe1DvGpsfdKyizQ3I1H9PXGJCVk5JUtD/P30FUdQ7V9b7wSTnoqOeuklu5N19K96Zr23U5FNvHUoIuCdUnbYPWKCpS7jaNRANDYUZwAAKbo1MJf30zsq1krD+qlBXu17uAJDX9tme4ZEKMHLm113mUlv6hE87el6OuNR7TqwDEZxqnlnm4uurxDqK7v1kK9o5uotLREP5bs0xVX9NehE4VatCdNi/eka93B4zp4LF+zVh7UrJUH5W6z6uKYIPVvHaRQX3d52V3lZXeVt91VXnaX3391lc2Fy4YBwJlRnAAApnF1sequ/tG6omMzTf1mu37dlaZ/L9qv77Ym69mRHdWvddAZn1fqMJRdUKysgmJlnv41v0jL9mXox21HlV/031n7+kQ30XVxLXRFh1B52f/7v73S3zexWCxqHeKj1iE+untAjHILS7Rif4YW70nTot3pSsk+qd92p+m33Wnn3Bc3V2tZmfJyc1Wwr7uu6dxcwzuGytON/90CQEPHf8kBAKYL8/fQO7d11887UvXktzt06Fi+xr63Rpdc1FQebi6/F6NTBSkrv1g5hSXnfL2IJp66rlsLjeoapvBAz2pl8ba7alj7UA1rHyrDMLQnNUeLdqdr/cHjyiooVm5hifKKSpRXWKrcwhIVlTgkSUUlDh0vKdLx388I3J2Sc+rUv2936OouzXVjj3B1DPOTxVI713EBAGoXxQkAUC9YLBZd3iFUfVs10b9+2asPVh3Uoj3nnrLc2+4qPw+bfD1s8vewKbqpl0Z1DVNcRECNFBSLxaK2ob5qG+orKeaM2xSXOpRXWHKqUP1epvIKS7T1SKa+WH9Eicfz9emaRH26JlFtQ310Y49wjewaJn9PtwvOBwCoOxQnAEC94uNu05PXtNf1cS20dF+6vNxOlSM/T9upX38vSb4etnpxXZHNxSp/T7cKRWhAm6a6f1ArrU44ptnrDmv+9hTtTsnRk9/t1HPzd+vy9qG6sUe4ekc3qbXZBNEwlDpOzfqYdKJAYQEeigj0VFMfO0cngXqG4gQAqJc6hPmpQ5if2TEuiNVq0cUxQbo4JkhP5Rdr3uYkfb7usHYdzda3W5L17ZZkhQd6aHRcuEb3CFeIr7vZkVFHikocWn3gmOZvT9GCnSnKyC0qt97dZlXLQE+1DPRSRBPPU79v4qmIQE+FBXjI7spMj0BdozgBAFAH/Dxtuv3iSN3WJ0Lbk7I1e32ivtmUrMPHC/SvBXs1Y0m8pl/XSdd0bm52VNSSk8WlWrI3XT9vT9Gvu1KVffK/1+r5uruqbTNfJZ0o0NGsAp0sdmhvaq72puZWeB2LRWru56H2zX016KJgDbqoqZr7e9TlrgCNEsUJAIA6ZLFY1LGFnzq26Kgnhsdq/vaj+mDlQW05kqU/fbZJ6xKO629XteOIQj1TVOLQ/rRcGTLKpqD3trvK7mo95yl1OSeL9dvuNP28I0WLdqeroPi/Mz4Gebvpsvahurx9qPrENCk79bSoxKGkzAIdOpanw8fzdehYvhKPn/o5dCxfBcWlSsosUFJmgX7ZmSpJuijER4MuaqpBFwWre2RAvTiNFXA2FCcAAEzi4eaia7u10DWdm+vlX/fqjUXx+mj1IW05kqk3bu5W7RkBUXOSMwu0KTFTmxJPaNPhTG1LyiqbQfGPXKwWebn9935ef7zHV35RqdYcOK6i0v8+L8zfQ8Pah+qKjqHq1jJALme4vs3N1aqoIC9FBXlVWGcYhjJyi3TwWJ5Wxx/T4r3p2pR4QntSc7QnNUf/WXpA3nZX9WsVVFakQv04BRSoCRQnAABM5upi1V+GtVX3yEA9Mnuzth7J0pWvLdNLo7toSGyI2fGc3sniUm1LyjpVkhIztSkxUynZJyts5+vuKrvNRXmFJWX3Cit1GMo+WVLutLv/Fd3US1d0CNXl7ZupQ5jvBU36YLFY1NTHrqY+dvWIDNSDg1srM79IS/dlaPHuNC3Zm65jeUX6aUeKftqRIklqG+qjS9oGq1+rIMVFBJz3zaWBxo7iBABAPXHJRcH64U/9NfGTjdp8OFN3fbhe9wyM1qOXXVRnp14ZhqESh+G0p3qVOgztT8vV1iOnjiJtPpypncnZKnEY5bZzsVrUNtRHXVv6q1vLAHVtGaDIJp5lpafUYSi/qPwU9GXT0heVKLewVA6HoYtjmqh1iE+t7pO/p5uu6dxc13RuLofD0LakLC3ek65Fe9K05UimdqfkaHdKjt5aHC83F6u6tPRXn+gm6hPTRF1b+nNaKFBFFCcAAOqRMH8PfXFPHz0/f7dmrkjQf5Yc0MZDJ/T6Td1q/JSrwpJS7U/L1c7kbO08mq1dR7O1MzlbOYUlCvP3UHRTb0UHeSmmqdep3zf1Uqive4OZJtvhMHQgI0/bkjK19UiWth3J0o7k7HLXGZ0W5G1Xt5b+6toyQN1a+qtjCz95up39a5KL1SIfd5t83G21uQvVZrVa1DncX53D/fXQkNY6lluoZfsytGRvulbGZyg1u1BrE45rbcJxvbpwn+yuVsVFBJQVqU4t/OXm6pylGbhQFCcAAOoZN1erplwdqx6RAXrsq61ad/CErnxtmV69sav6tQ46r9c8kVd0qhj9Xo52Hs3W/rTcCkdaTjtyokBHThRo6d7yNyH2dHNRVNCpIhX1e6lq39xPMU29TClUxaUOZRUUK6ugWMdyCrQxw6KtP+3R9uQc7UjOVm5hxVPovNxc1D7MT53C/NQp3F/dWvorzN+jwRTC6mjibdfIrmEa2TVMhmEoISNPqw8c16oDx7Qq/pgycgu1Mv6YVsYfkxZIHjYXdY8MUL9WQbqpV0v51rNieDb5RSU6kJ6nAxl5yjlZrMFtQ7i2CzWO4gQAQD11RcdmatfMV/d9slG7jmbr1plr9NDg1nrw0tZnnFQgK79Yh47nlc2+lvj7bGwJGXlnvGZHOnXdTmxzX7Vr5qvYZr6Kbe6rIG+7Dmac+hJ6ID1XB9LzlJCRp0PH85VfVKodydnakZxd7nVCfd3Vr3WQ+rcOUr9WQWribb+gfU/LOaltR7K0JzVHmfnFysovVmZB0e8lqURZ+ad+n1f0v0ePXKR9h8oeudus6tDcTx1b+KlTCz91DPNXVJDXGT8/Z2exWH4/cuitm3u1lGEYik/P1ar4Y1p14JhWHziu43lFWrYvQ8v2Zej9FQf19MgOGlpPrrMrdRhKOZ6v+N//TB7I+O+fzaNZ5f98T7Hu0JB2wbqlV4T6tQriJtOoERQnAADqscggL829/2I9+e0Ofb7usF75dZ82HDqhKzs206Hfp6hOPJavQ8fyzjlBgSS1DPRUbLPfS1LzUz/N/c586l2Ir7t6RTcpt6y41KHE4/mnvrT+/uU1Pj1XW5OylJJ9Ul9tOKKvNhyRJMU281X/1kHq37qpukeee0KCY7mF2pZ06lS6rb//eraidzY+dlf5ebjKtaRA/dq3VOfwAHVq4a+Ypl5yddLrtS6UxWJRq2AftQr20a19IuVwGNqblqNV8cf04apDSsjI04QP1+vKjs009ZpYBfvUzREcwzB0NOukdiafOn10R3KWthxw0V/WLTzjzIanBXjaFN3UWw7D0KbETP28I1U/70hVy0BP3dyrpW6Ia3HBhR6NG8UJAIB6zt3mouev66QekYH627ztZUcEzqSpj10RgZ5qGeiplk1O/RrRxFNtQnwu+Hocm4tVMU29FdPUW9J/j0KcLC7V2oTjWr7/VK6yUwKPZus/Sw/I7mpVz6hA9W8dpD7RQcoqKNbWpMxTRelIlpIyCyq8l8UitQ72VmwzXzX1scvPw3bqx9Ot7Pf+v//q4+4qVxeriouL9eOPP2r48Hay2RrGKWb1idVqUdtQX7UN9dVNPVvq1YX79PbSA/ph21Et35+hJ65spxviWtToKY2n74/1x2vsdh7NVlZB8f9saZHkkJuLVRFNPBV9+rq7oP/+GuDlVrb13tQcfbomUV9vPKLE4/l6fv5u/euXPbq8QzPd0qulekUFOuWpmahdFCcAABqI6+JaqGMLP73w0x4VlzoU8XsxOlWOvBQe6HHOCQ1qi7vNRQPaNNWANk0lSek5hVoZn6GlezO0fH+6UrMLz1n2pFNTdncK81PHFv7q1MJPsc185WXna4pZ3G0u+r/L2+qqTs30f19v1fakbD321VZ9szlJz43qqIgmFe8xVRVHTuRr0e40bT6c9ft1djkqLq14nZ2L1aLWwd5q18xXbYK9dOLQLo2+YqCimvpW6TTLNiE+evKa9nrs8ov0/Zaj+mTNIW05kqXvtiTruy3JimnqpVt6Rei6bi3k50nJRtXwXyQAABqQNiE+evf27mbHOKemPnaN6BKmEV1OTUiwPy1Xy/ZlaPn+DK1LOK5Abzd1DPvvNUftw3wbzCQEjU375n6ad39fzVyRoJcW7NWK/cc07JWlmjS0jcb3jar0NMjT06P/uitVv+5K066j2RW28XF3LX8KaTNftQr2Lju9s7i4WD9m71REoGe1r03zdHPV6B7hGt0jXNuTsvTJmkR9szlJ8el5eur7nfrHT7t1TefmGtc3SrHNfav12mh8KE4AAKDWWCwWtQ7xUesQH43vF2V2HJwHVxer7h4Qo2HtQzV5zjatjD+m537cre+2HNXz13VU++Z+5bY/WVyqlfEZWrAzTQt3pSotp7BsndUidY8IVJ+YJmr/+6QkLQLqZkbDDmF+mn5tR/11eFvN25ysT1Yf0u6UHH254Yi+3HBEfaKbaHy/KA1uG8xkEjgjihMAAAAqFdHES5/c1Utfrj+iZ37YqW1JWbrm3yt094Boje0doRX7M/TrzlQt25dR7l5ZXm4uGnhRUw1uG6JL2gYr8A/XIpnBx92mW3tHaGyvltqYmKlZKw/qx21HT03RfuCYIpt46o6LI3VD93BOF0U5/GkAAABAlVgsFo3uEa5BbZtq2rc79cO2o3prcbzeWhxfbrtmfu4a0i5EQ2JD1Ds6UHbXs8+qaBaLxaK4iADFRQRo8hVt9eGqQ/psbaIOHsvXk9/t1L8W7NWNPcJ1+8WRahHgaXZc1AOmz8/5xhtvKDIyUu7u7urVq5fWrl171m137Nih6667TpGRkbJYLHrllVfqLigAAAAkScE+7nrjlm56+9Y4hfiemuK7Y5ifHhnSRt8/2E8rH79UT4/soIFtmtbL0vS/mvt76PEr2mrV5FO5o4O8lHOyRO8sS9CAFxbp/k82aMOh4zKMM98wGo2DqUecZs+erUmTJmnGjBnq1auXXnnlFQ0bNkx79uxRcHBwhe3z8/MVHR2tG264QY888ogJiQEAAHDaZe1DdWnbYOUVljrF7HSebq66tXeEbunZUov3pmnm8oNavj9DP25L0Y/bUtS5hZ+u7x6ui2OaKDrIiynNGxlTi9NLL72kCRMmaNy4cZKkGTNm6IcfftDMmTP1+OOPV9i+R48e6tGjhySdcT0AAADqlquLVX6epp/EVKOsVosubRuiS9uGaHdKtt5fflBzNydpy5EsbTmSJUkK9rGrT0wT9Y5uoj7RTRTRxJMi5eRMK05FRUXasGGDJk+eXLbMarVqyJAhWrVqVY29T2FhoQoL/zubS3b2qWkwi4uLVVz8vzdXq3unM9SHLKgZjKnzYUydE+PqfBhT52T2uMY08dAzI9rpkcHR+mpjspbtz9Cmw1lKyynUN5uT9c3mZElSqK9dvaMC1Ss6UL2jAtUiwMOUvA2B2WP6R9XJYFpxysjIUGlpqUJCQsotDwkJ0e7du2vsfaZPn65p06ZVWP7LL7/I07P+XOi3YMECsyOghjGmzocxdU6Mq/NhTJ1TfRjXcEk3h0o3BEsHcyzal23R/iyLDuZKKdmFmrflqOZtOSpJCrQbau1rqFOgobb+hlyd66BcjagPY5qfn1/lbZ1+Vr3Jkydr0qRJZY+zs7MVHh6uyy67TL6+5t/orLi4WAsWLNDQoUNlszX8c4PBmDojxtQ5Ma7OhzF1Tg1hXAuKSrXxcKbWHDiu1QnHtS0pW8cLpTXpFq1Jl/w9bLq8Q4iu6dRMcS39G/19ourTmJ4+G60qTCtOQUFBcnFxUWpqarnlqampCg0NrbH3sdvtstvtFZbbbDbTB+qP6lseXDjG1Pkwps6JcXU+jKlzqs/jarPZNKhtqAa1PfUdNq+wROsOHtfSvRn6fmuy0nIK9fm6I/p83RGF+Xvomi7NNbJLmC4K9TE5ubnqw5hW5/1NO2jo5uamuLg4LVy4sGyZw+HQwoUL1adPH7NiAQAAABfEy+6qQRcFa8rVsVo1ebA+vrOXro9rIW+7q5IyC/TW4ngNe2WpLn9lqWYsiVdyZoHZkVEFpp6qN2nSJN1+++3q3r27evbsqVdeeUV5eXlls+zddtttCgsL0/Tp0yWdmlBi586dZb9PSkrS5s2b5e3trVatWpm2HwAAAMCZuFgt6tc6SP1aB+mZkR302+40zduUpEV70rQ7JUfPz9+t5+fvVs+oQI3qGqaRXcLk4Vb/733VGJlanMaMGaP09HRNmTJFKSkp6tKli3766aeyCSMSExNltf73oFhycrK6du1a9vjFF1/Uiy++qIEDB2rx4sV1HR8AAACoMnebi4Z3bKbhHZspK79YP24/qnmbkrQm4bjW/v7z4s97NK5vpG7tEyk/j/p5amJjZfrkEA888IAeeOCBM6773zIUGRnJHZsBAADQ4Pl52nRTz5a6qWdLJWcW6NstyfpkzSEdPl6gF3/ZqxlLDmhs7wiN7xepYB93s+NCJl7jBAAAAEBq7u+hewfGaNGfB+mVMV10UYiPcgtLNGNJvPr9Y5H+Nm+bDh+v+rTZqB0UJwAAAKAecHWxamTXMM1/qL/eua27urb0V1GJQx+vTtSgFxfr4c83aU9KjtkxGy3TT9UDAAAA8F9Wq0VDY0M0pF2wVh84rjcX79eyfRmatzlZ8zYna0i7EN1/SYy6tQwwO2qjQnECAAAA6iGLxaI+MU3UJ6aJth3J0ltL9mv+9hT9uitVv+5KVe/oQN0/qJX6tw6SxdK4b6pbFyhOAAAAQD3XsYWf3rwlTvHpuZqxOF5zNyVp9YHjWn1grTqG+en+QTEa1j5UVisFqrZwjRMAAADQQMQ09dY/b+ispY9donF9I+Vhc9G2pCzd98lGDXl5ib5Yf1hFJQ6zYzolihMAAADQwDT399DUq9trxeOX6k+XtpKvu6sOpOfpsa+2atA/F2nm8gTlF5WYHdOpUJwAAACABirQy02TLrtIKycP1l+Ht1Wwj13JWSf11Pc71e8fi/T6wn3Kyi82O6ZToDgBAAAADZy33VV3D4jR0scu0bOjOqhloKeO5xXpXwv26uLnF2r6j7uUln3S7JgNGsUJAAAAcBLuNhfd0itCv/15oF69sYvahvoor6hU/1l6QH3/8Zsmzd6s7UlZZsdskJhVDwAAAHAyri5WjegSpms6N9eiPWl6a3G81h08oTmbkjRnU5J6RgVqfN8oDY0Nkct5zsSXVVCs33an6qftKTpyokBDY0N0Q/dwhfl71PDe1A8UJwAAAMBJWSwWXdo2RJe2DdHWI5mauTxB3289qrUJx7U24bjCAz10x8VRGt29hXzcbZW+XkZuoRbsTNX87SlauT9DJQ6jbN2O5Gy9unCf+rduqjHdwzUkNlh2V5fa3L06RXECAAAAGoFOLfz1yo1d9fgV7fThqoP6dG2iDh8v0NPf79TLC/ZqdPdw3XFxpFo28Sz3vOTMAv20PUU/7UjR+oPH9YeupDYh3rq8fahaBHpq3qYkrYw/pqV707V0b7oCvdw0qmuYxvQIV5sQnzre25pHcQIAAAAakVA/dz12eVs9eGlrzd2UpJkrErQ/LVczVyRo1soEDY0N0Zge4dqdkqOft6doy5Hy10R1auGnYe1DdXmHUMU09S5bPrp7uBKP5euL9Yf15YbDSs0u1HvLE/Te8gR1bemvG3uE68pOzWVvoLMsUJwAAACARsjDzUU392qpG3uEa+m+dM1ccVBL96br5x2p+nlHatl2FovUIyJQwzqEalj7ELUI8Dzra7Zs4qlHh12kh4e01tJ96fp87WH9tjtNmxIztSkxU9O+26nhHULVokgyDOOsr1MfUZwAAACARsxqtWjQRcEadFGw9qXmaOaKg/ptd6rahPjo8g6huiw2VE197NV6TVcXa9m1Vek5hZqz8YhmrzusAxl5+mpjkiRX9e6dqd6tgmtnp2oBxQkAAACAJKl1iI+mX9tRUscae82mPnbdMzBGdw+I1vpDJ/TpmkNavSdJXcP9a+w96gLFCQAAAECts1gs6hEZqC5hPvr+h0RZz3MadLM00EuzAAAAADRUDawzSaI4AQAAAEClKE4AAAAAUAmKEwAAAABUguIEAAAAAJWgOAEAAABAJShOAAAAAFAJihMAAAAAVILiBAAAAACVoDgBAAAAQCUoTgAAAABQCYoTAAAAAFSC4gQAAAAAlaA4AQAAAEAlKE4AAAAAUAmKEwAAAABUguIEAAAAAJWgOAEAAABAJVzNDlDXDMOQJGVnZ5uc5JTi4mLl5+crOztbNpvN7DioAYyp82FMnRPj6nwYU+fEuDqf+jSmpzvB6Y5wLo2uOOXk5EiSwsPDTU4CAAAAoD7IycmRn5/fObexGFWpV07E4XAoOTlZPj4+slgsZsdRdna2wsPDdfjwYfn6+podBzWAMXU+jKlzYlydD2PqnBhX51OfxtQwDOXk5Kh58+ayWs99FVOjO+JktVrVokULs2NU4Ovra/ofHNQsxtT5MKbOiXF1Poypc2JcnU99GdPKjjSdxuQQAAAAAFAJihMAAAAAVILiZDK73a6pU6fKbrebHQU1hDF1Poypc2JcnQ9j6pwYV+fTUMe00U0OAQAAAADVxREnAAAAAKgExQkAAAAAKkFxAgAAAIBKUJwAAAAAoBIUJxO98cYbioyMlLu7u3r16qW1a9eaHQnVsHTpUl199dVq3ry5LBaL5s2bV269YRiaMmWKmjVrJg8PDw0ZMkT79u0zJyyqZPr06erRo4d8fHwUHByskSNHas+ePeW2OXnypCZOnKgmTZrI29tb1113nVJTU01KjMq89dZb6tSpU9lNFvv06aP58+eXrWc8G77nn39eFotFDz/8cNkyxrXhefLJJ2WxWMr9tG3btmw9Y9owJSUlaezYsWrSpIk8PDzUsWNHrV+/vmx9Q/uuRHEyyezZszVp0iRNnTpVGzduVOfOnTVs2DClpaWZHQ1VlJeXp86dO+uNN9444/oXXnhBr732mmbMmKE1a9bIy8tLw4YN08mTJ+s4KapqyZIlmjhxolavXq0FCxaouLhYl112mfLy8sq2eeSRR/Tdd9/pyy+/1JIlS5ScnKxrr73WxNQ4lxYtWuj555/Xhg0btH79el166aUaMWKEduzYIYnxbOjWrVun//znP+rUqVO55Yxrw9S+fXsdPXq07Gf58uVl6xjThufEiRPq27evbDab5s+fr507d+pf//qXAgICyrZpcN+VDJiiZ8+exsSJE8sel5aWGs2bNzemT59uYiqcL0nG3Llzyx47HA4jNDTU+Oc//1m2LDMz07Db7cZnn31mQkKcj7S0NEOSsWTJEsMwTo2hzWYzvvzyy7Jtdu3aZUgyVq1aZVZMVFNAQIDx7rvvMp4NXE5OjtG6dWtjwYIFxsCBA42HHnrIMAz+njZUU6dONTp37nzGdYxpw/R///d/Rr9+/c66viF+V+KIkwmKioq0YcMGDRkypGyZ1WrVkCFDtGrVKhOToaYkJCQoJSWl3Bj7+fmpV69ejHEDkpWVJUkKDAyUJG3YsEHFxcXlxrVt27Zq2bIl49oAlJaW6vPPP1deXp769OnDeDZwEydO1JVXXllu/CT+njZk+/btU/PmzRUdHa1bbrlFiYmJkhjThurbb79V9+7ddcMNNyg4OFhdu3bVO++8U7a+IX5XojiZICMjQ6WlpQoJCSm3PCQkRCkpKSalQk06PY6MccPlcDj08MMPq2/fvurQoYOkU+Pq5uYmf3//ctsyrvXbtm3b5O3tLbvdrnvvvVdz585VbGws49mAff7559q4caOmT59eYR3j2jD16tVLs2bN0k8//aS33npLCQkJ6t+/v3JychjTBurAgQN666231Lp1a/3888+677779Kc//UkffPCBpIb5XcnV7AAAUB9NnDhR27dvL3eOPRqmiy66SJs3b1ZWVpa++uor3X777VqyZInZsXCeDh8+rIceekgLFiyQu7u72XFQQ6644oqy33fq1Em9evVSRESEvvjiC3l4eJiYDOfL4XCoe/fueu655yRJXbt21fbt2zVjxgzdfvvtJqc7PxxxMkFQUJBcXFwqzAaTmpqq0NBQk1KhJp0eR8a4YXrggQf0/fffa9GiRWrRokXZ8tDQUBUVFSkzM7Pc9oxr/ebm5qZWrVopLi5O06dPV+fOnfXqq68yng3Uhg0blJaWpm7dusnV1VWurq5asmSJXnvtNbm6uiokJIRxdQL+/v5q06aN9u/fz9/VBqpZs2aKjY0tt6xdu3Zlp2A2xO9KFCcTuLm5KS4uTgsXLixb5nA4tHDhQvXp08fEZKgpUVFRCg0NLTfG2dnZWrNmDWNcjxmGoQceeEBz587Vb7/9pqioqHLr4+LiZLPZyo3rnj17lJiYyLg2IA6HQ4WFhYxnAzV48GBt27ZNmzdvLvvp3r27brnllrLfM64NX25uruLj49WsWTP+rjZQffv2rXBLj7179yoiIkJSA/2uZPbsFI3V559/btjtdmPWrFnGzp07jbvvvtvw9/c3UlJSzI6GKsrJyTE2bdpkbNq0yZBkvPTSS8amTZuMQ4cOGYZhGM8//7zh7+9vfPPNN8bWrVuNESNGGFFRUUZBQYHJyXE29913n+Hn52csXrzYOHr0aNlPfn5+2Tb33nuv0bJlS+O3334z1q9fb/Tp08fo06ePialxLo8//rixZMkSIyEhwdi6davx+OOPGxaLxfjll18Mw2A8ncUfZ9UzDMa1Ifrzn/9sLF682EhISDBWrFhhDBkyxAgKCjLS0tIMw2BMG6K1a9carq6uxrPPPmvs27fP+OSTTwxPT0/j448/LtumoX1XojiZ6PXXXzdatmxpuLm5GT179jRWr15tdiRUw6JFiwxJFX5uv/12wzBOTbP597//3QgJCTHsdrsxePBgY8+ePeaGxjmdaTwlGe+//37ZNgUFBcb9999vBAQEGJ6ensaoUaOMo0ePmhca5zR+/HgjIiLCcHNzM5o2bWoMHjy4rDQZBuPpLP63ODGuDc+YMWOMZs2aGW5ubkZYWJgxZswYY//+/WXrGdOG6bvvvjM6dOhg2O12o23btsbbb79dbn1D+65kMQzDMOdYFwAAAAA0DFzjBAAAAACVoDgBAAAAQCUoTgAAAABQCYoTAAAAAFSC4gQAAAAAlaA4AQAAAEAlKE4AAAAAUAmKEwAAAABUguIEAMAFmjVrlvz9/c2OAQCoRRQnAECdSUlJ0UMPPaRWrVrJ3d1dISEh6tu3r9566y3l5+ebHa9KIiMj9corr5RbNmbMGO3du9ecQACAOuFqdgAAQONw4MAB9e3bV/7+/nruuefUsWNH2e12bdu2TW+//bbCwsJ0zTXXmJLNMAyVlpbK1fX8/rfo4eEhDw+PGk4FAKhPOOIEAKgT999/v1xdXbV+/XqNHj1a7dq1U3R0tEaMGKEffvhBV199tSQpMzNTd911l5o2bSpfX19deuml2rJlS9nrPPnkk+rSpYs++ugjRUZGys/PTzfeeKNycnLKtnE4HJo+fbqioqLk4eGhzp0766uvvipbv3jxYlksFs2fP19xcXGy2+1avny54uPjNWLECIWEhMjb21s9evTQr7/+Wva8QYMG6dChQ3rkkUdksVhksVgknflUvbfeeksxMTFyc3PTRRddpI8++qjceovFonfffVejRo2Sp6enWrdurW+//bbGPm8AQM2iOAEAat2xY8f0yy+/aOLEifLy8jrjNqdLyA033KC0tDTNnz9fGzZsULdu3TR48GAdP368bNv4+HjNmzdP33//vb7//nstWbJEzz//fNn66dOn68MPP9SMGTO0Y8cOPfLIIxo7dqyWLFlS7j0ff/xxPf/889q1a5c6deqk3NxcDR8+XAsXLtSmTZt0+eWX6+qrr1ZiYqIkac6cOWrRooWeeuopHT16VEePHj3jvsydO1cPPfSQ/vznP2v79u265557NG7cOC1atKjcdtOmTdPo0aO1detWDR8+XLfccku5/QQA1CMGAAC1bPXq1YYkY86cOeWWN2nSxPDy8jK8vLyMxx57zFi2bJnh6+trnDx5stx2MTExxn/+8x/DMAxj6tSphqenp5GdnV22/i9/+YvRq1cvwzAM4+TJk4anp6excuXKcq9x5513GjfddJNhGIaxaNEiQ5Ixb968SrO3b9/eeP3118seR0REGC+//HK5bd5//33Dz8+v7PHFF19sTJgwodw2N9xwgzF8+PCyx5KMv/3tb2WPc3NzDUnG/PnzK80EAKh7XOMEADDN2rVr5XA4dMstt6iwsFBbtmxRbm6umjRpUm67goICxcfHlz2OjIyUj49P2eNmzZopLS1NkrR//37l5+dr6NCh5V6jqKhIXbt2Lbese/fu5R7n5ubqySef1A8//KCjR4+qpKREBQUFZUecqmrXrl26++67yy3r27evXn311XLLOnXqVPZ7Ly8v+fr6lu0HAKB+oTgBAGpdq1atZLFYtGfPnnLLo6OjJalsYoXc3Fw1a9ZMixcvrvAaf7yGyGazlVtnsVjkcDjKXkOSfvjhB4WFhZXbzm63l3v8v6cNPvroo1qwYIFefPFFtWrVSh4eHrr++utVVFRUxT2tnnPtBwCgfqE4AQBqXZMmTTR06FD9+9//1oMPPnjW65y6deumlJQUubq6KjIy8rzeKzY2Vna7XYmJiRo4cGC1nrtixQrdcccdGjVqlKRTJezgwYPltnFzc1Npaek5X6ddu3ZasWKFbr/99nKvHRsbW608AID6g+IEAKgTb775pvr27avu3bvrySefVKdOnWS1WrVu3Trt3r1bcXFxGjJkiPr06aORI0fqhRdeUJs2bZScnKwffvhBo0aNqnBq3Zn4+Pjo0Ucf1SOPPCKHw6F+/fopKytLK1askK+vb7ky879at26tOXPm6Oqrr5bFYtHf//73CkeAIiMjtXTpUt14442y2+0KCgqq8Dp/+ctfNHr0aHXt2lVDhgzRd999pzlz5pSboQ8A0LBQnAAAdSImJkabNm3Sc889p8mTJ+vIkSOy2+2KjY3Vo48+qvvvv18Wi0U//vijnnjiCY0bN07p6ekKDQ3VgAEDFBISUuX3evrpp9W0aVNNnz5dBw4ckL+/v7p166a//vWv53zeSy+9pPHjx+viiy9WUFCQ/u///k/Z2dnltnnqqad0zz33KCYmRoWFhTIMo8LrjBw5Uq+++qpefPFFPfTQQ4qKitL777+vQYMGVXkfAAD1i8U403/xAQAAAABluI8TAAAAAFSC4gQAAAAAlaA4AQAAAEAlKE4AAAAAUAmKEwAAAABUguIEAAAAAJWgOAEAAABAJShOAAAAAFAJihMAAAAAVILiBAAAAACVoDgBAAAAQCX+H8KBlKuT0viWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evo_diffusion.synthetic_sequences import visualize_sequence_metric, average_a_content, gc_content\n",
    "\n",
    "fig, ax = visualize_sequence_metric(all_sequences, gc_content)\n",
    "\n",
    "# With selection for 'A', we expect a decrease in GC content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8b79d-d536-4522-91ae-124db19e5843",
   "metadata": {},
   "source": [
    "## Preparing Data for PyTorch Training\n",
    "\n",
    "To train a model on sequence evolution, we format the data for PyTorch:\n",
    "\n",
    "1. Extract Parent-Child Pairs – Link each child sequence to its parent and record the generation time step.\n",
    "2. One-Hot Encode Sequences – Convert nucleotide sequences into numerical form for model processing.\n",
    "3. Generate training and test sets for the sequences.\n",
    "4. Create PyTorch Tensors and DataLoader – Store data as tensors and batch it with a DataLoader for training.\n",
    "\n",
    "This setup enables neural networks to learn evolutionary patterns from genetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de6f2d9-3cf1-46f1-8007-d28c7990196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import numpy as np\n",
    "\n",
    "def generate_training_pairs(all_sequences, parent_child_indices):\n",
    "    \"\"\"\n",
    "    Generate parent-child training pairs and corresponding time steps using explicit indices.\n",
    "\n",
    "    Args:\n",
    "        all_sequences: List of arrays, where each array has shape \n",
    "                       (num_sequences, sequence_length) and corresponds to a generation.\n",
    "        parent_child_indices: List of arrays, where each array has shape (num_sequences,)\n",
    "                              and indicates the parent index for each child in the next generation.\n",
    "\n",
    "    Returns:\n",
    "        parents: Array of parent sequences (num_pairs, sequence_length).\n",
    "        children: Array of child sequences (num_pairs, sequence_length).\n",
    "        time_steps: Array of time steps for each pair (num_pairs,).\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    children = []\n",
    "    time_steps = []\n",
    "\n",
    "    for t in range(len(all_sequences) - 1):\n",
    "        # Parent generation and child generation\n",
    "        parent_gen = all_sequences[t]\n",
    "        child_gen = all_sequences[t + 1]\n",
    "\n",
    "        # Get the parent-child relationships for this generation\n",
    "        parent_indices = parent_child_indices[t]\n",
    "\n",
    "        # Retrieve the parent sequences based on indices\n",
    "        current_parents = parent_gen[parent_indices]\n",
    "\n",
    "        # Store parents, children, and time steps\n",
    "        parents.extend(current_parents)\n",
    "        children.extend(child_gen)\n",
    "        time_steps.extend([t + 1] * len(child_gen))  # Time step is t+1 for the child\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    parents = np.array(parents)\n",
    "    children = np.array(children)\n",
    "    time_steps = np.array(time_steps)\n",
    "\n",
    "    return parents, children, time_steps\n",
    "\n",
    "def one_hot_encode(sequences, vocab):\n",
    "    \"\"\"\n",
    "    Convert sequences to one-hot encoding.\n",
    "\n",
    "    Args:\n",
    "        sequences: Array of sequences (num_sequences, sequence_length), where each residue\n",
    "                   is a character (e.g., 'A', 'C', 'G', 'T').\n",
    "        vocab: List of unique residues (e.g., ['A', 'C', 'G', 'T']).\n",
    "\n",
    "    Returns:\n",
    "        one_hot: Array of one-hot encoded sequences (num_sequences, sequence_length, vocab_size).\n",
    "    \"\"\"\n",
    "    # Create a mapping from residues to integer indices\n",
    "    vocab_size = len(vocab)\n",
    "    char_to_index = {char: idx for idx, char in enumerate(vocab)}\n",
    "\n",
    "    # Initialize one-hot encoding array\n",
    "    num_sequences, sequence_length = sequences.shape\n",
    "    one_hot = np.zeros((num_sequences, sequence_length, vocab_size), dtype=np.float32)\n",
    "\n",
    "    # Convert each character to its corresponding index and one-hot encode\n",
    "    for i in range(num_sequences):\n",
    "        for j in range(sequence_length):\n",
    "            residue = sequences[i, j]\n",
    "            if residue in char_to_index:  # Handle unexpected residues gracefully\n",
    "                one_hot[i, j, char_to_index[residue]] = 1.0\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected residue '{residue}' in sequence.\")\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "# Define the vocabulary\n",
    "vocab = ['A', 'C', 'G', 'T']  # Nucleotide bases\n",
    "\n",
    "parents, children, time_steps = generate_training_pairs(all_sequences, parent_child_indices)\n",
    "parents_one_hot = one_hot_encode(parents, vocab)\n",
    "children_one_hot = one_hot_encode(children, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8d975f-4704-4dec-bf8e-f37e881007fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split parent-child pairs and time steps\n",
    "parents_train, parents_val, children_train, children_val, time_train, time_val = train_test_split(\n",
    "    parents_one_hot, children_one_hot, time_steps, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259b139d-15c9-4666-bd90-491b71de6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "parents_train_tensor = torch.tensor(parents_train, dtype=torch.float32)\n",
    "children_train_tensor = torch.tensor(children_train, dtype=torch.float32)\n",
    "time_train_tensor = torch.tensor(time_train, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch dataset and dataloader\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(parents_train_tensor, children_train_tensor, time_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f1adba-fdf8-4371-898e-0de4b5935fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 50, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed87c9a-0f62-4ffb-9349-243d67139177",
   "metadata": {},
   "source": [
    "## Training the Diffusion Model\n",
    "\n",
    "The `DiffusionTrainer` class fits the `EditBasedDiffusion` model to predict how genetic sequences evolve over time. It trains the model to simulate mutations and selection by learning how parent sequences generate offspring and how to reverse this process.\n",
    "\n",
    "### How the Trainer Works\n",
    "\n",
    "- The model predicts how parent sequences evolve into children using a forward process.\n",
    "- It also reconstructs parents from children using a reverse process to enforce consistency.\n",
    "\n",
    "- Random noise is introduced during training to simulate natural genetic mutations.\n",
    "- The model learns to apply edits based on these noisy inputs.\n",
    "\n",
    "### Loss\n",
    "\n",
    "The model loss is computed for both forward and reverse processes, ensuring the model captures sequence transitions in both directions.\n",
    "The loss function accounts for mutation-driven randomness while preserving meaningful structure in the sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9268e21a-fb40-4708-a25e-dabdae632dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "class DiffusionTrainer:\n",
    "    def __init__(self, model, lr=0.001, alpha=1.0, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \"\"\"\n",
    "        Trainer class for the EditBasedDiffusion model with time dependency.\n",
    "\n",
    "        Args:\n",
    "            model: The diffusion model to train.\n",
    "            lr: Learning rate for the optimizer.\n",
    "            alpha: Hyperparameter for mutation weighting.\n",
    "            device: Device to train on ('cuda' or 'cpu').\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.alpha = alpha\n",
    "        self.device = device\n",
    "\n",
    "    def compute_mutation_weights(self, parents, children):\n",
    "        \"\"\"\n",
    "        Compute mutation-based weights for all parent-child pairs.\n",
    "\n",
    "        Args:\n",
    "            parents: Parent sequences (batch_size, sequence_length).\n",
    "            children: Child sequences (batch_size, sequence_length).\n",
    "\n",
    "        Returns:\n",
    "            weights: Pairwise weight matrix (batch_size, batch_size).\n",
    "        \"\"\"\n",
    "        hamming_distances = (parents != children).sum(dim=-1)\n",
    "        weights = torch.exp(-self.alpha * hamming_distances)  # Exponential weighting\n",
    "        return weights\n",
    "\n",
    "    def compute_loss(self, parents, children, t):\n",
    "        \"\"\"\n",
    "        Compute the weighted loss for the forward and reverse processes with time dependency.\n",
    "\n",
    "        Args:\n",
    "            parents: Parent sequences (batch_size, sequence_length, num_residues).\n",
    "            children: Child sequences (batch_size, sequence_length, num_residues).\n",
    "            t: Time step tensor (batch_size, 1).\n",
    "\n",
    "        Returns:\n",
    "            loss: Weighted loss value.\n",
    "        \"\"\"\n",
    "        # Predict child sequences from parents (forward process)\n",
    "        noise_forward = torch.randn(parents.shape[0], parents.shape[1], self.model.embedding_dim, device=parents.device)\n",
    "        forward_field = self.model.forward_edit_field(parents, t, noise_forward)\n",
    "        predicted_children = self.model.apply_edits(parents, forward_field)\n",
    "\n",
    "        # Predict parent sequences from children (reverse process)\n",
    "        noise_reverse = torch.randn(children.shape[0], children.shape[1], self.model.embedding_dim, device=children.device)\n",
    "        reverse_field = self.model.reverse_edit_field(children, t, noise_reverse)\n",
    "        predicted_parents = self.model.apply_edits(children, reverse_field)\n",
    "\n",
    "        # Compute mutation-based weights\n",
    "        #weights = self.compute_mutation_weights(parents.argmax(dim=-1), children.argmax(dim=-1))\n",
    "\n",
    "        # Compute loss of forward and reverse networks\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        weighted_loss = loss_fn(torch.log(predicted_children), children) + loss_fn(torch.log(predicted_parents), parents)\n",
    "\n",
    "        #reg_loss = forward_field.pow(2).sum() + reverse_field.pow(2).sum()\n",
    "        total_loss = weighted_loss # + 0.01 * reg_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def train_one_epoch(self, dataloader):\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "\n",
    "        Args:\n",
    "            dataloader: DataLoader for training data.\n",
    "\n",
    "        Returns:\n",
    "            avg_loss: Average loss for the epoch.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for parents, children, t in dataloader:\n",
    "            # Move data to device\n",
    "            parents = parents.to(self.device)\n",
    "            children = children.to(self.device)\n",
    "            t = t.to(self.device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(parents, children, t)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        return avg_loss\n",
    "\n",
    "    def fit(self, dataloader, epochs=10):\n",
    "        \"\"\"\n",
    "        Train the model for a specified number of epochs.\n",
    "\n",
    "        Args:\n",
    "            dataloader: DataLoader for training data.\n",
    "            epochs: Number of epochs to train.\n",
    "\n",
    "        Returns:\n",
    "            loss_history: List of average loss values per epoch.\n",
    "        \"\"\"\n",
    "        loss_history = []\n",
    "        for epoch in range(epochs):\n",
    "            avg_loss = self.train_one_epoch(dataloader)\n",
    "            loss_history.append(avg_loss)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fd4fd-a0c1-488a-b7d0-3cf4109d7b46",
   "metadata": {},
   "source": [
    "## EditBasedDiffusion\n",
    "\n",
    "The `EditBasedDiffusion` model is a bidirectional diffusion model designed for learning sequence evolution. It operates in an embedding space, where forward diffusion models the progression of genetic sequences over time, and reverse diffusion reconstructs ancestral sequences. The model ensures that sampled sequences follow a learned distribution aligned with observed evolutionary transitions.\n",
    "\n",
    "### Shared Sequence Embedding Network\n",
    "The model maps discrete sequences to a continuous embedding space using a Transformer-based encoder:  \n",
    "$$\n",
    "f_{\\text{seq}}: \\mathbb{R}^{L \\times N} \\to \\mathbb{R}^{L \\times D}\n",
    "$$\n",
    "where $L$ is the sequence length, $N$ is the number of possible residues (e.g., \\( N=4 \\) for DNA bases), and $D$ is the embedding dimension.  \n",
    "\n",
    "To capture **global sequence-level properties**, a **learnable CLS token** $c \\in \\mathbb{R}^{1 \\times D}$ is prepended, producing:  \n",
    "$$\n",
    "S = \\text{Concat}(c, f_{\\text{seq}}(x)) \\in \\mathbb{R}^{(L+1) \\times D}.\n",
    "$$  \n",
    "\n",
    "This sequence embedding provides a structured latent space where evolutionary dynamics can be learned.  \n",
    "\n",
    "### Temporal Embedding Network\n",
    "The model encodes time using a sinusoidal embedding:  \n",
    "$$\n",
    "f_{\\text{time}}: \\mathbb{R}^{1} \\to \\mathbb{R}^{D}.\n",
    "$$\n",
    "This produces a **shared temporal representation** \\( T \\in \\mathbb{R}^{B \\times D} \\) that aligns with the sequence embedding space.  \n",
    "\n",
    "This enables the model to **condition sequence evolution on time**, allowing it to learn time-dependent selection dynamics.  \n",
    "\n",
    "### Attention-Based Fusion of Sequence and Time Representations\n",
    "The sequence and time embeddings are fused using **multi-head attention**, treating  $T$ as the query and \\( S \\) as key and value:  \n",
    "$$\n",
    "\\text{Attention}(T, S, S) \\in \\mathbb{R}^{B \\times D}.\n",
    "$$  \n",
    "This produces:  \n",
    "- A **time-aware CLS token** encoding the **global sequence state** conditioned on time.  \n",
    "- An **updated sequence embedding** where each position is refined using information from the global context.  \n",
    "\n",
    "This step ensures that both **local sequence features** and **global evolutionary constraints** are incorporated into the learned representation.  \n",
    "\n",
    "### Stochastic Diffusion Step: Noise Injection and Transition Modeling \n",
    "To **model mutations and uncertainty**, the model perturbs the sequence embedding using Gaussian noise:  \n",
    "$$\n",
    "S' = S + \\eta, \\quad \\eta \\sim \\mathcal{N}(0, I)\n",
    "$$  \n",
    "where $S'$ represents the **noisy embedding** that serves as input for the next sequence state.  \n",
    "\n",
    "A **transition function** (implemented via an MLP) then maps this perturbed embedding to an **edit field**:  \n",
    "\n",
    "$$\n",
    "e = f_{\\text{edit}}(S') \\in \\mathbb{R}^{L \\times N}.\n",
    "$$  \n",
    "This edit field represents **probabilities of mutations** at each position in the sequence.  \n",
    "\n",
    "To **sample new sequences**, we apply a transformation that ensures the output matches the observed training distribution:  \n",
    "$$\n",
    "x_t = \\operatorname{softmax}(\\log(x + \\epsilon) + e),\n",
    "$$\n",
    "where $\\epsilon$ prevents numerical instability.  \n",
    "\n",
    "This step ensures that generated sequences **maintain realistic evolutionary constraints**, aligning the learned distribution with observed genetic transitions.  \n",
    "\n",
    "### Forward and Reverse Diffusion Processes\n",
    "The model operates bidirectionally to simulate sequence evolution:  \n",
    "\n",
    "- **Forward process**: Given an input sequence $x_t$, predict $x_{t+1}$ by:  \n",
    "  1. Encoding it into **latent space**.  \n",
    "  2. Injecting **stochastic noise** to simulate mutations.  \n",
    "  3. Predicting an **edit field** using a learned transformation.  \n",
    "  4. Sampling a **new sequence** using the softmax transformation above.  \n",
    "\n",
    "- **Reverse process**: Given an observed sequence at time $t$, reconstruct its ancestral state $x_{t-1}$ by inverting the transition process.  \n",
    "\n",
    "This **bidirectional learning** ensures that the model captures **mutation-driven evolution** while preserving **ancestral reconstruction capability**.  \n",
    "\n",
    "## **How This Relates to Evolution**  \n",
    "The **EditBasedDiffusion** model simulates **mutation and selection dynamics** by learning a structured latent space where\n",
    "- **Mutations are modeled as stochastic perturbations** in the embedding space.  \n",
    "- **Selection is implicitly encoded** through learned edit fields.  \n",
    "- **Time-dependent constraints** allow adaptation to changing selection pressures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65ee1e-4f46-4950-97ac-5629f268955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137120\n",
      "Epoch 1/100, Loss: 80.8400\n"
     ]
    }
   ],
   "source": [
    "from evo_diffusion.edit_based_diffusion import EditBasedDiffusion\n",
    "\n",
    "# Initialize the model\n",
    "embedding_dim = 256\n",
    "feedforward_dim = 512\n",
    "transformer_params = {\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_layers\": 2,\n",
    "    \"feedforward_dim\": feedforward_dim\n",
    "}\n",
    "\n",
    "mlp_params = {\"feedforward_dim\": [feedforward_dim] * 2, \"activation\": \"ReLU\"}\n",
    "\n",
    "model =  EditBasedDiffusion(sequence_length, 4, embedding_dim, transformer_params, mlp_params)\n",
    "\n",
    "def count_parameters(model):\n",
    "  total_params = 0\n",
    "  for param in model.parameters():\n",
    "    total_params += param.numel()\n",
    "  return total_params\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = DiffusionTrainer(model, lr=4e-4, alpha=0.01)\n",
    "\n",
    "# Train the model\n",
    "loss_history = trainer.fit(train_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ae031-30dd-4376-a24e-c9e8a7bb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9131f85-3555-42ad-b656-7cabd8d80837",
   "metadata": {},
   "source": [
    "## Evaluating the Model and Generating Predictions\n",
    "\n",
    "Once the model is trained, we assess its ability to simulate sequence evolution by comparing its predictions to our data. \n",
    "\n",
    "### Sampling Sequences from Model Predictions\n",
    "- Given a probability distribution over possible residues, we sample sequences using multinomial sampling.\n",
    "- This ensures that generated sequences reflect realistic evolutionary variation.\n",
    "\n",
    "### Comparing Mutation Rates\n",
    "- The model’s predicted mutation rates are compared to actual parent-child mutation rates from the simulated data.\n",
    "- This helps validate whether the model captures realistic patterns of genetic change.\n",
    "\n",
    "### Simulating Future Generations\n",
    "- The trained model is used to generate entire populations over multiple generations.\n",
    "- This allows us to visualize how sequence composition evolves over time, tracking properties of the population like GC content and mean fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad6820-2ba8-43b4-884e-b44b12f8a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def sample_sequence_from_probabilities(probabilities):\n",
    "    \"\"\"\n",
    "    Samples a sequence from predicted probabilities using multinomial sampling.\n",
    "    \n",
    "    Args:\n",
    "        probabilities (torch.Tensor): Predicted probabilities of shape (batch_size, sequence_length, num_residues).\n",
    "\n",
    "    Returns:\n",
    "        sampled_indices (torch.Tensor): Sampled residue indices of shape (batch_size, sequence_length).\n",
    "    \"\"\"\n",
    "    batch_size, sequence_length, num_residues = probabilities.shape\n",
    "\n",
    "    # Flatten the probabilities for sampling\n",
    "    probabilities_flat = probabilities.view(-1, num_residues)  # (batch_size * sequence_length, num_residues)\n",
    "\n",
    "    # Sample residue indices for each position\n",
    "    sampled_indices_flat = torch.multinomial(probabilities_flat, num_samples=1).squeeze(-1)  # (batch_size * sequence_length,)\n",
    "\n",
    "    # Reshape back to the original sequence format\n",
    "    sampled_indices = sampled_indices_flat.view(batch_size, sequence_length)  # (batch_size, sequence_length)\n",
    "\n",
    "    return sampled_indices\n",
    "\n",
    "def map_indices_to_strings_numpy(indices, vocab):\n",
    "    \"\"\"\n",
    "    Map sequence indices back to their string representations and return as a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        indices: Array or tensor of shape (batch_size, sequence_length).\n",
    "        vocab: List or array of string representations (e.g., ['A', 'C', 'G', 'T']).\n",
    "\n",
    "    Returns:\n",
    "        mapped_sequences: NumPy array of shape (batch_size, sequence_length), where each element\n",
    "                          is the string representation of the corresponding index.\n",
    "    \"\"\"\n",
    "    if isinstance(indices, torch.Tensor):\n",
    "        indices = indices.numpy()  # Convert tensor to numpy array if necessary\n",
    "\n",
    "    # Create a vectorized function to map indices to strings\n",
    "    vectorized_mapping = np.vectorize(lambda idx: vocab[idx])\n",
    "\n",
    "    # Apply the mapping\n",
    "    mapped_sequences = vectorized_mapping(indices)\n",
    "\n",
    "    return mapped_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02da20-c695-4b05-aae5-18437931504b",
   "metadata": {},
   "source": [
    "## Comparing mutation rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88311bfa-bf08-4aac-b8f2-22252594f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_mutation_rate_comparison(all_sequences, parent_child_indices, model, time_steps):\n",
    "    \"\"\"\n",
    "    Compare the mutation rates between actual parent-child pairs and model-predicted pairs.\n",
    "\n",
    "    Args:\n",
    "        all_sequences: List of actual sequences over time steps.\n",
    "        parent_child_indices: List of parent-child indices for each generation.\n",
    "        model: Trained diffusion model.\n",
    "        time_steps: List of time steps to evaluate.\n",
    "    \"\"\"\n",
    "    actual_mutation_rates = []\n",
    "    predicted_mutation_rates = []\n",
    "\n",
    "    for t in time_steps:\n",
    "        parent_gen = all_sequences[t - 1]\n",
    "        child_gen = all_sequences[t]\n",
    "        parent_indices = parent_child_indices[t - 1]\n",
    "\n",
    "        # Actual parent-child pairs\n",
    "        actual_parents = parent_gen[parent_indices]\n",
    "        actual_children = child_gen\n",
    "\n",
    "        # Predict child sequences using the model\n",
    "        actual_parents_one_hot = torch.tensor(one_hot_encode(actual_parents, vocab))\n",
    "\n",
    "        t_tensor = torch.tensor([[t]] * len(actual_parents)).float()\n",
    "        t_tensor = t_tensor[:, 0]\n",
    "\n",
    "        predicted_children_onehot = model.forward(actual_parents_one_hot, t_tensor)\n",
    "        predicted_children = predicted_children_onehot.argmax(dim=-1)\n",
    "        predicted_children = sample_sequence_from_probabilities(predicted_children_onehot)\n",
    "\n",
    "        # Compute actual mutation rate\n",
    "        actual_mutations = (actual_parents != actual_children).sum()\n",
    "        actual_mutation_rate = actual_mutations / actual_parents.shape[0]\n",
    "        actual_mutation_rates.append(actual_mutation_rate)\n",
    "\n",
    "        # Compute predicted mutation rate\n",
    "        predicted_children = map_indices_to_strings_numpy(predicted_children, vocab)\n",
    "        predicted_mutations = (actual_parents != predicted_children).sum().item()\n",
    "        predicted_mutation_rate = predicted_mutations / actual_parents.shape[0]\n",
    "        predicted_mutation_rates.append(predicted_mutation_rate)\n",
    "\n",
    "    # Plot mutation rates\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time_steps, actual_mutation_rates, label=\"Actual Mutation Rate\", marker=\"o\")\n",
    "    plt.plot(time_steps, predicted_mutation_rates, label=\"Predicted Mutation Rate\", marker=\"x\")\n",
    "    plt.axhline( mutation_rate * sequence_length, label=\"Theoretical mutation rate\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Mutation Rate\")\n",
    "    plt.title(\"Comparison of Mutation Rates Over Time (Parent-Child)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "time_steps = range(1, len(all_sequences))  # Exclude the initial sequence\n",
    "plot_mutation_rate_comparison(all_sequences, parent_child_indices, model, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762265a-68d6-4048-825d-d53840ba1d21",
   "metadata": {},
   "source": [
    "## One-step evolution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01366668-ad8d-49b6-a99a-d383ee55b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence_evolution_comparison(all_sequences, parent_child_indices, model, vocab, num_samples=5):\n",
    "    \"\"\"\n",
    "    Compare sequence evolution between actual and model-predicted sequences.\n",
    "\n",
    "    Args:\n",
    "        all_sequences: List of arrays, where each array contains sequences for one generation.\n",
    "        parent_child_indices: List of arrays, where each array maps parent indices to children.\n",
    "        model: Trained diffusion model with a forward method.\n",
    "        vocab: List of characters representing the sequence alphabet (e.g., ['A', 'C', 'G', 'T']).\n",
    "        num_samples: Number of sequences to sample for comparison.\n",
    "    \"\"\"\n",
    "    time_steps = len(all_sequences) - 1  # Number of generations\n",
    "    sample_indices = np.random.choice(len(all_sequences[0]), num_samples, replace=False)  # Sample sequences\n",
    "\n",
    "    actual_sequences = []\n",
    "    predicted_sequences = []\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        actual_sample_sequence = []\n",
    "        predicted_sample_sequence = []\n",
    "\n",
    "        # Initialize the current sequence with one-hot encoding\n",
    "        #current_sequence = all_sequences[0][idx]  # Integer-encoded sequence\n",
    "        #current_sequence_one_hot = torch.tensor(one_hot_encode(current_sequence[None, :], vocab), dtype=torch.float32)\n",
    "\n",
    "        # Track actual and predicted sequences over time\n",
    "        for t in range(1, time_steps + 1):\n",
    "            parent_gen = all_sequences[t - 1]\n",
    "            child_gen = all_sequences[t]\n",
    "            parent_indices = parent_child_indices[t - 1]\n",
    "\n",
    "            # Actual parent-child pair\n",
    "            actual_parent = parent_gen[parent_indices[idx]]\n",
    "            actual_child = child_gen[idx]\n",
    "\n",
    "            current_sequence_one_hot = torch.tensor(one_hot_encode(parent_gen, vocab), dtype=torch.float32)\n",
    "\n",
    "            # Predict child sequence\n",
    "            t_tensor = torch.tensor([[t]] * parent_gen.shape[0], dtype=torch.float32)  # Time tensor\n",
    "            predicted_child_one_hot = model.forward(current_sequence_one_hot, t_tensor[:,0])\n",
    "            predicted_child = predicted_child_one_hot.argmax(dim=-1).numpy()\n",
    "            predicted_child = sample_sequence_from_probabilities(predicted_child_one_hot)\n",
    "            \n",
    "            # Store actual and predicted sequences\n",
    "            actual_sample_sequence.append(actual_child)\n",
    "            predicted_sample_sequence.append(predicted_child)\n",
    "\n",
    "            # Update the current sequence for the next step\n",
    "            #current_sequence_one_hot = predicted_child_one_hot\n",
    "\n",
    "        actual_sequences.append(np.array(actual_sample_sequence))\n",
    "        predicted_sequences.append(np.array(predicted_sample_sequence))\n",
    "\n",
    "\n",
    "    # Plot evolution using numerical indices for heatmaps\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    vocab_map = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    for i in range(num_samples):\n",
    "        # Convert sequences to integer arrays for visualization\n",
    "        actual_sequence_numeric = np.array([[vocab_map[str(char)] for char in seq] for seq in actual_sequences[i]])\n",
    "        predicted_sequence_numeric = predicted_sequences[i][:,0,:]\n",
    "\n",
    "        plt.subplot(num_samples, 2, i * 2 + 1)\n",
    "        plt.imshow(actual_sequence_numeric, aspect=\"auto\", cmap=\"viridis\")\n",
    "        plt.colorbar(label=\"Residue Index\")\n",
    "        plt.ylabel(\"Time Step\")\n",
    "        plt.title(f\"Sample {i + 1} Actual Evolution\")\n",
    "\n",
    "        plt.subplot(num_samples, 2, i * 2 + 2)\n",
    "        plt.imshow(predicted_sequence_numeric, aspect=\"auto\", cmap=\"viridis\")\n",
    "        plt.colorbar(label=\"Residue Index\")\n",
    "        plt.ylabel(\"Time Step\")\n",
    "        plt.title(f\"Sample {i + 1} Predicted Evolution\")\n",
    "\n",
    "    plt.xlabel(\"Sequence Position\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_sequence_evolution_comparison(all_sequences, parent_child_indices, model, vocab, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f985e8-2e4f-4e1a-8e12-011560200c6e",
   "metadata": {},
   "source": [
    "## Visualizing sequence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f6431-5e20-43d5-87da-4dc0959157e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Function to subsample the tensors for PCA analysis\n",
    "def subsample_tensors(parents_tensor, children_tensor, times_tensor, sample_size=100):\n",
    "    \"\"\"\n",
    "    Subsample the parent-child tensors and their corresponding times.\n",
    "\n",
    "    Args:\n",
    "        parents_tensor: Tensor of parent sequences (batch_size, sequence_length, num_residues).\n",
    "        children_tensor: Tensor of child sequences (batch_size, sequence_length, num_residues).\n",
    "        times_tensor: Tensor of time steps corresponding to the sequences (batch_size, 1).\n",
    "        sample_size: Number of samples to subsample.\n",
    "\n",
    "    Returns:\n",
    "        sequences: Subsampled tensor of sequences.\n",
    "        times: Subsampled tensor of times.\n",
    "    \"\"\"\n",
    "    indices = torch.randperm(parents_tensor.size(0))[:sample_size]\n",
    "    sequences = torch.cat((parents_tensor[indices], children_tensor[indices]), dim=0)\n",
    "    times = torch.cat((times_tensor[indices], times_tensor[indices]), dim=0)\n",
    "    return sequences, times\n",
    "\n",
    "def get_time_aware_cls(model, x, fixed_time):\n",
    "    \"\"\"\n",
    "    Get the time-aware CLS token for a fixed time.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input sequence (batch_size, sequence_length, num_residues).\n",
    "        fixed_time (float): A fixed time value to compute the time embedding.\n",
    "\n",
    "    Returns:\n",
    "        time_aware_cls (torch.Tensor): Time-aware CLS token (batch_size, embedding_dim).\n",
    "    \"\"\"\n",
    "    # Convert the fixed time to a tensor\n",
    "    batch_size = x.size(0)\n",
    "    t_tensor = torch.tensor([fixed_time] * batch_size, device=x.device, dtype=torch.float32)  # (batch_size, 1)\n",
    "\n",
    "    # Embed sequence and add CLS token\n",
    "    seq_with_cls = model.embed_sequence(x)  # (batch_size, sequence_length + 1, embedding_dim)\n",
    "\n",
    "    # Embed the fixed time\n",
    "    time_embedding = model.embed_time(t_tensor)\n",
    "    print(time_embedding.shape)\n",
    "\n",
    "    # Combine embeddings using attention to get the time-aware CLS token\n",
    "    time_aware_cls, _ = model.combine_embeddings(seq_with_cls, time_embedding, model.forward_attention)\n",
    "\n",
    "    return time_aware_cls\n",
    "    \n",
    "# PCA plotting function using the model's `embed_sequence`\n",
    "def plot_pca_of_embeddings(model, sequences, times, num_components=2):\n",
    "    \"\"\"\n",
    "    Perform PCA on the embeddings generated by the model using `embed_sequence` and plot them.\n",
    "\n",
    "    Args:\n",
    "        model: The trained diffusion model with the `embed_sequence` method.\n",
    "        sequences: Input sequences as one-hot tensors (batch_size, sequence_length, num_residues).\n",
    "        times: Sampling times corresponding to each sequence (batch_size, 1).\n",
    "        num_components: Number of principal components to compute (default: 2).\n",
    "    \"\"\"\n",
    "    # Generate embeddings using the model's `embed_sequence` method\n",
    "    #embeddings = model.embed_sequence(sequences).detach().cpu().numpy()  # Shape: (batch_size, embedding_dim)\n",
    "    embeddings = get_time_aware_cls(model, sequences, 0).detach().cpu().numpy()\n",
    "    print(embeddings.shape)\n",
    "    embeddings = embeddings[:, :]\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    principal_components = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Variance explained by each principal component\n",
    "    explained_variance = pca.explained_variance_ratio_ * 100\n",
    "\n",
    "    # Plot PCA\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        principal_components[:, 0],\n",
    "        principal_components[:, 1],\n",
    "        c=times.squeeze().numpy(),  # Use sampling times for coloring\n",
    "        cmap=\"viridis\",\n",
    "        edgecolor=\"k\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.colorbar(scatter, label=\"Time of Sampling\")\n",
    "    plt.xlabel(f\"PC1 ({explained_variance[0]:.2f}% Variance Explained)\")\n",
    "    plt.ylabel(f\"PC2 ({explained_variance[1]:.2f}% Variance Explained)\")\n",
    "    plt.title(\"PCA of Model Embeddings Colored by Sampling Time\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with subsampled data\n",
    "sample_size = 500  # Adjust based on your dataset size\n",
    "\n",
    "# Subsample the tensors\n",
    "sequences, times = subsample_tensors(parents_train_tensor, children_train_tensor, time_train_tensor, sample_size)\n",
    "\n",
    "# Plot PCA\n",
    "plot_pca_of_embeddings(model, sequences, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9fed54-db5d-4021-a3f9-42cbdd049244",
   "metadata": {},
   "source": [
    "## Sampling population trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f6e7c-a612-48c9-b7b8-84030f721f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_forward(model, x_0, t_target):\n",
    "    \"\"\"\n",
    "    Efficiently sample sequences forward in time to t_target.\n",
    "\n",
    "    Args:\n",
    "        model: The diffusion model.\n",
    "        x_0: Base sequence (batch_size, sequence_length, num_residues).\n",
    "        t_target: Target time to evolve the sequence to.\n",
    "\n",
    "    Returns:\n",
    "        x_t: Sequence evolved to time t_target.\n",
    "    \"\"\"\n",
    "    # Create time tensor for t_target\n",
    "    t = torch.tensor([[t_target]] * x_0.size(0), device=x_0.device, dtype=torch.float32)\n",
    "    \n",
    "    # Generate edit field for the target time\n",
    "    #edit_field = model.forward_edit_field(x_0, t)\n",
    "    \n",
    "    # Apply edits to evolve sequences to the target time\n",
    "    #x_t = model.apply_edits(x_0, edit_field)\n",
    "    x_t = model.forward(x_0, t[:,0])\n",
    "    return sample_sequence_from_probabilities(x_t)\n",
    "\n",
    "\n",
    "def generate_population(model, all_sequences, num_generations, batch_size):\n",
    "    \"\"\"\n",
    "    Generate replicate populations across generations using the model efficiently.\n",
    "\n",
    "    Args:\n",
    "        model: The trained diffusion model.\n",
    "        all_sequences: Initial sequences for the population (generation 0).\n",
    "        num_generations: Number of generations to simulate.\n",
    "        batch_size: Number of sequences in each batch.\n",
    "\n",
    "    Returns:\n",
    "        replicate_populations: List of sequences for each generation.\n",
    "    \"\"\"\n",
    "    # Initialize the first generation\n",
    "    x_0 = torch.tensor(one_hot_encode(all_sequences[0], vocab), dtype=torch.float32)\n",
    "    replicate_populations = [all_sequences[0]]  # Store all generations\n",
    "\n",
    "    current_population = x_0.clone()  # Start with the initial population\n",
    "\n",
    "    for gen in range(num_generations):\n",
    "        # Randomly sample a batch from the current population\n",
    "        sampled_indices = np.random.choice(current_population.size(0), batch_size, replace=False)\n",
    "        x_start = current_population[sampled_indices]\n",
    "\n",
    "        # Evolve the sampled batch to the next generation\n",
    "        x_next = sample_forward(model, x_start, t_target=gen+1)  # Move forward by 1 generation\n",
    "\n",
    "        # Store the new generation\n",
    "        x_next_seq = map_indices_to_strings_numpy(x_next.detach(), vocab)\n",
    "        replicate_populations.append(x_next_seq)\n",
    "\n",
    "        # Update current population for the next iteration\n",
    "        current_population = torch.tensor(one_hot_encode(x_next_seq, vocab), dtype=torch.float32)\n",
    "        #current_population = torch.tensor(one_hot_encode(all_sequences[gen+1], vocab), dtype=torch.float32)\n",
    "\n",
    "    return replicate_populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f69229-50a5-4505-a756-a860b08733f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate populations for all generations\n",
    "replicate_populations = generate_population(\n",
    "    model=model,\n",
    "    all_sequences=all_sequences,\n",
    "    num_generations=time_span,\n",
    "    batch_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7569674-4611-4d5b-9f8e-6ce9dc596f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays for further analysis\n",
    "replicate_populations_np = [x for x in replicate_populations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de59a5-acc4-49dc-9a6c-c45203eb6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo_diffusion.synthetic_sequences import visualize_sequence_metric, average_a_content, gc_content\n",
    "\n",
    "fig, ax = visualize_sequence_metric(all_sequences, gc_content)\n",
    "visualize_sequence_metric(replicate_populations_np, gc_content, ax=ax,  title=\"GC Content Over Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def mean_fitness(population, generation):\n",
    "    return example_fitness_function(population, generation).mean()\n",
    "\n",
    "fig, ax = visualize_sequence_metric(all_sequences, mean_fitness, time_dependent_metric=True)\n",
    "visualize_sequence_metric(replicate_populations_np, mean_fitness, ax=ax,  title=\"Mean fitness\", time_dependent_metric=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d10222-9e49-418f-8d73-f3dd0bdabc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac9f0b-222f-4494-bef9-f46232aa10a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69cfd4-c663-4cb4-a8a1-9d16f5823527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd1d6b-89b4-487c-bee4-b2bcf545a966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
